{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e19a5d-65d7-44bc-a6d7-c6f0a7916129",
   "metadata": {},
   "source": [
    "# Flight Delay Prediction and Analysis Using PySpark and AWS  \n",
    "### [Dataset Source: US DOT Flight Delays on Kaggle](https://www.kaggle.com/datasets/usdot/flight-delays/data)\n",
    "\n",
    "---\n",
    "\n",
    "## About the Dataset\n",
    "\n",
    "### **Context**\n",
    "The U.S. Department of Transportation's (DOT) Bureau of Transportation Statistics tracks the on-time performance of domestic flights operated by large air carriers. This dataset specifically captures information on flight delays, cancellations, and diversions from the year 2015. Summary information regarding on-time performance is regularly published in the DOT's monthly Air Travel Consumer Report.\n",
    "\n",
    "### **Acknowledgements**\n",
    "The flight delay and cancellation data was collected and published by the DOT's Bureau of Transportation Statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80900843-4fd8-439b-b273-eddfab05ebed",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Installation of Required Python Libraries**\n",
    "\n",
    "This code cell installs specific Python libraries into the Spark environment at runtime, ensuring all necessary dependencies are available for subsequent data processing and analysis tasks.\n",
    "\n",
    "**Installed Packages:**\n",
    "\n",
    "| Package              | Version    | Purpose                                                  |\n",
    "|----------------------|------------|----------------------------------------------------------|\n",
    "| `python-dateutil`    | `2.8.2`    | Utilities for parsing, manipulating, and formatting dates|\n",
    "| `numpy`              | Latest     | Numerical operations and array manipulations             |\n",
    "| `pandas`             | Latest     | Data analysis, manipulation, and DataFrame management    |\n",
    "| `matplotlib`         | Latest     | Data visualization and plotting                          |\n",
    "| `boto3`              | Latest     | AWS SDK for Python, used to interact with AWS services   |\n",
    "| `fsspec`             | Latest     | File system specification interface for Python           |\n",
    "| `s3fs`               | Latest     | Pythonic file system interface to Amazon S3              |\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- These libraries extend Spark’s capabilities, enabling advanced data processing, numerical computations, visualization, and seamless integration with cloud storage services (AWS S3).\n",
    "- Explicitly specifying the version (`2.8.2`) for `python-dateutil` ensures compatibility and reproducibility.\n",
    "- Using `sc.install_pypi_package()` allows dynamic package installation at runtime within a PySpark environment, ensuring these libraries are available across all Spark executors.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0252b92-f3ae-4c8b-8fe4-8fdea40e9b92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T18:08:40.654014Z",
     "iopub.status.busy": "2025-03-13T18:08:40.653677Z",
     "iopub.status.idle": "2025-03-13T18:10:57.386779Z",
     "shell.execute_reply": "2025-03-13T18:10:57.385547Z",
     "shell.execute_reply.started": "2025-03-13T18:08:40.653981Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde87a43909c4554b976d31c967a8e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody><tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1741886625437_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-36-202.ec2.internal:20888/proxy/application_1741886625437_0002/\" class=\"emr-proxy-link j-UYZTTV0S1OZ7 application_1741886625437_0002\" emr-resource=\"j-UYZTTV0S1OZ7\n",
       "\" application-id=\"application_1741886625437_0002\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-40-7.ec2.internal:8042/node/containerlogs/container_1741886625437_0002_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dateutil==2.8.2\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil==2.8.2) (1.13.0)\n",
      "Installing collected packages: python-dateutil\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Not uninstalling python-dateutil at /usr/lib/python3.9/site-packages, outside environment /mnt/yarn/usercache/livy/appcache/application_1741886625437_0002/container_1741886625437_0002_01_000001/tmp/spark-bf5122bd-a3ff-4b6d-9e23-3282eb84fdfc\n",
      "    Can't uninstall 'python-dateutil'. No files were found to uninstall.\n",
      "Successfully installed python-dateutil-2.8.2\n",
      "\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.0.2\n",
      "\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./tmp/spark-bf5122bd-a3ff-4b6d-9e23-3282eb84fdfc/lib64/python3.9/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./tmp/spark-bf5122bd-a3ff-4b6d-9e23-3282eb84fdfc/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.13.0)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2025.1\n",
      "\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Requirement already satisfied: numpy>=1.23 in ./tmp/spark-bf5122bd-a3ff-4b6d-9e23-3282eb84fdfc/lib64/python3.9/site-packages (from matplotlib) (2.0.2)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting pillow>=8\n",
      "  Downloading pillow-11.1.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.56.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./tmp/spark-bf5122bd-a3ff-4b6d-9e23-3282eb84fdfc/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Collecting zipp>=3.1.0\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.13.0)\n",
      "Installing collected packages: zipp, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.56.0 importlib-resources-6.5.2 kiwisolver-1.4.7 matplotlib-3.9.4 pillow-11.1.0 zipp-3.21.0\n",
      "\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.37.11-py3-none-any.whl (139 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/site-packages (from boto3) (1.0.1)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0\n",
      "  Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
      "Collecting botocore<1.38.0,>=1.37.11\n",
      "  Downloading botocore-1.37.11-py3-none-any.whl (13.4 MB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/lib/python3.9/site-packages (from botocore<1.38.0,>=1.37.11->boto3) (1.25.10)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./tmp/spark-bf5122bd-a3ff-4b6d-9e23-3282eb84fdfc/lib/python3.9/site-packages (from botocore<1.38.0,>=1.37.11->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.11->boto3) (1.13.0)\n",
      "Installing collected packages: botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.37.11 botocore-1.37.11 s3transfer-0.11.4\n",
      "\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Installing collected packages: fsspec\n",
      "Successfully installed fsspec-2025.3.0\n",
      "\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2025.3.0-py3-none-any.whl (30 kB)\n",
      "Collecting aiobotocore<3.0.0,>=2.5.4\n",
      "  Downloading aiobotocore-2.21.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: fsspec==2025.3.0.* in ./tmp/spark-bf5122bd-a3ff-4b6d-9e23-3282eb84fdfc/lib/python3.9/site-packages (from s3fs) (2025.3.0)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.11.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Collecting multidict<7.0.0,>=6.0.0\n",
      "  Downloading multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Collecting botocore<1.37.2,>=1.37.0\n",
      "  Downloading botocore-1.37.1-py3-none-any.whl (13.4 MB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./tmp/spark-bf5122bd-a3ff-4b6d-9e23-3282eb84fdfc/lib/python3.9/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (2.8.2)\n",
      "Collecting wrapt<2.0.0,>=1.10.10\n",
      "  Downloading wrapt-1.17.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Collecting aioitertools<1.0.0,>=0.5.1\n",
      "  Downloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (20.3.0)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.18.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting typing_extensions>=4.0\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/lib/python3.9/site-packages (from botocore<1.37.2,>=1.37.0->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.25.10)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.13.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3.9/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.10)\n",
      "Installing collected packages: typing-extensions, propcache, multidict, frozenlist, yarl, async-timeout, aiosignal, aiohappyeyeballs, wrapt, botocore, aioitertools, aiohttp, aiobotocore, s3fs\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.37.11\n",
      "    Uninstalling botocore-1.37.11:\n",
      "      Successfully uninstalled botocore-1.37.11\n",
      "Successfully installed aiobotocore-2.21.1 aiohappyeyeballs-2.6.1 aiohttp-3.11.13 aioitertools-0.12.0 aiosignal-1.3.2 async-timeout-5.0.1 botocore-1.37.1 frozenlist-1.5.0 multidict-6.1.0 propcache-0.3.0 s3fs-2025.3.0 typing-extensions-4.12.2 wrapt-1.17.2 yarl-1.18.3\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3transfer 0.11.4 requires botocore<2.0a.0,>=1.37.4, but you have botocore 1.37.1 which is incompatible.\n",
      "boto3 1.37.11 requires botocore<1.38.0,>=1.37.11, but you have botocore 1.37.1 which is incompatible."
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"python-dateutil==2.8.2\")\n",
    "sc.install_pypi_package(\"numpy\")\n",
    "sc.install_pypi_package(\"pandas\")\n",
    "sc.install_pypi_package(\"matplotlib\")\n",
    "sc.install_pypi_package(\"boto3\")\n",
    "sc.install_pypi_package(\"fsspec\")\n",
    "sc.install_pypi_package(\"s3fs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b03d6-4f36-4c84-b3a5-b2b0dffff34c",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **Importing Necessary Libraries for Data Analysis and Modeling**\n",
    "\n",
    "This cell imports essential libraries and functions required for data manipulation, preprocessing, visualization, and machine learning model implementation using PySpark and Python.\n",
    "\n",
    "**Imported Libraries and Functions:**\n",
    "\n",
    "| Library/Function                                | Purpose / Usage                                            |\n",
    "|-------------------------------------------------|------------------------------------------------------------|\n",
    "| `pyspark.sql.SparkSession`                      | Entry point to interact with Spark DataFrames and SQL operations |\n",
    "| `pyspark.sql.functions as F`                    | Provides built-in PySpark DataFrame functions for transformations |\n",
    "| `pyspark.sql.functions.when`                    | Conditional expressions (similar to SQL CASE WHEN)         |\n",
    "| `pyspark.sql.functions.col, sum`                | Column-based DataFrame operations and aggregation functions |\n",
    "| `matplotlib.pyplot as plt`                      | Data visualization and plotting                            |\n",
    "| `pandas as pd`                                  | Data manipulation, analysis, and conversion between PySpark and Pandas DataFrames |\n",
    "| `boto3`                                         | AWS SDK for Python; interacting with AWS services (e.g., S3)|\n",
    "| `time`                                          | Tracking execution times, timestamps, or delays            |\n",
    "| `pyspark.sql.types.IntegerType`                 | Explicitly defining or casting columns to integer data type|\n",
    "| `pyspark.ml.feature.StringIndexer`              | Converts categorical string columns into numeric indices   |\n",
    "| `pyspark.ml.feature.OneHotEncoder`              | Encodes categorical indices into one-hot encoded vectors   |\n",
    "| `pyspark.ml.feature.VectorAssembler`            | Combines multiple feature columns into a single vector     |\n",
    "| `pyspark.ml.Pipeline`                           | Combines multiple stages of machine learning workflow into a single, streamlined pipeline |\n",
    "| `pyspark.ml.classification.LogisticRegression`  | Implements Logistic Regression classifier for predictive modeling tasks |\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- **Data Manipulation & SQL Functions**:  \n",
    "  Imports PySpark's built-in functions to facilitate data manipulation (e.g., aggregations, transformations, conditional logic).\n",
    "\n",
    "- **Visualization & Analysis**:  \n",
    "  Incorporates `matplotlib` and `pandas` for exploratory data analysis (EDA), visualization, and converting Spark DataFrames to Pandas DataFrames for convenience in visualizing and exploring data.\n",
    "\n",
    "- **AWS Integration (`boto3`)**:  \n",
    "  Enables direct interaction with AWS cloud storage services such as S3, allowing for streamlined data retrieval/storage.\n",
    "\n",
    "- **Machine Learning & Preprocessing**:  \n",
    "  Prepares categorical data for machine learning by converting string categories to numerical indices (`StringIndexer`) and encoding them as vectors (`OneHotEncoder`), followed by assembling all features into a single vector suitable for Spark ML models (`VectorAssembler`). Utilizes Spark ML’s pipeline functionality to streamline this process.\n",
    "\n",
    "- **Logistic Regression**:  \n",
    "  Imports logistic regression, commonly used for classification tasks (binary or multiclass), as the machine learning algorithm for model training and predictions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c87666b3-ef1a-4cb8-9afa-05dc4ab02e9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T18:12:09.883746Z",
     "iopub.status.busy": "2025-03-13T18:12:09.883509Z",
     "iopub.status.idle": "2025-03-13T18:12:17.223576Z",
     "shell.execute_reply": "2025-03-13T18:12:17.222853Z",
     "shell.execute_reply.started": "2025-03-13T18:12:09.883719Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ca3702baa8482f9ba4f1fca14b6ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col, sum\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import boto3, time\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52372a18-9412-4be4-8c07-1a3b45485ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T18:29:11.265863Z",
     "iopub.status.busy": "2025-03-13T18:29:11.265632Z",
     "iopub.status.idle": "2025-03-13T18:29:11.369422Z",
     "shell.execute_reply": "2025-03-13T18:29:11.368348Z",
     "shell.execute_reply.started": "2025-03-13T18:29:11.265836Z"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### **Loading Data from Amazon S3 into Spark DataFrames**\n",
    "\n",
    "This cell reads three datasets directly from Amazon S3 into Spark DataFrames:\n",
    "\n",
    "- **`flights_df`**: Contains data related to flights.\n",
    "- **`airports_df`**: Contains information about airports.\n",
    "- **`airlines_df`**: Contains details about airlines.\n",
    "\n",
    "The datasets are loaded with:\n",
    "\n",
    "- Headers automatically detected (`header=true`).\n",
    "- Data types inferred automatically (`inferSchema=true`).\n",
    "\n",
    "We also have to make sure the provided S3 paths correctly point to the datasets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0256ee8-2a3b-4fc8-999f-5c6ff1fe8a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T18:39:00.101612Z",
     "iopub.status.busy": "2025-03-13T18:39:00.101371Z",
     "iopub.status.idle": "2025-03-13T18:39:45.863381Z",
     "shell.execute_reply": "2025-03-13T18:39:45.862568Z",
     "shell.execute_reply.started": "2025-03-13T18:39:00.101586Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e7a9727105427e85b86d523e72d151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read raw data from S3\n",
    "# (Make sure these S3 paths point to your dataset locations.)\n",
    "flights_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"s3://final-csc555/athena/flights.csv\")\n",
    "\n",
    "airports_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"s3://final-csc555/athena/airports.csv\")\n",
    "\n",
    "airlines_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"s3://final-csc555/athena/airlines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "668e0cf0-9324-4523-bfea-08bb4820ee40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T04:58:59.238060Z",
     "iopub.status.busy": "2025-03-13T04:58:59.237442Z",
     "iopub.status.idle": "2025-03-13T04:59:02.587092Z",
     "shell.execute_reply": "2025-03-13T04:59:02.586304Z",
     "shell.execute_reply.started": "2025-03-13T04:58:59.238027Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d879bb71e7a484b908e3a8db93b3970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|2015|    1|  1|          4|     AS|           98|     N407AS|           ANC|                SEA|                  5|          2354|            -11|      21|        15|           205|         194|     169|    1448|      404|      4|              430|         408|          -22|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|\n",
      "|2015|    1|  1|          4|     AA|         2336|     N3KUAA|           LAX|                PBI|                 10|             2|             -8|      12|        14|           280|         279|     263|    2330|      737|      4|              750|         741|           -9|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|\n",
      "|2015|    1|  1|          4|     US|          840|     N171US|           SFO|                CLT|                 20|            18|             -2|      16|        34|           286|         293|     266|    2296|      800|     11|              806|         811|            5|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|\n",
      "|2015|    1|  1|          4|     AA|          258|     N3HYAA|           LAX|                MIA|                 20|            15|             -5|      15|        30|           285|         281|     258|    2342|      748|      8|              805|         756|           -9|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|\n",
      "|2015|    1|  1|          4|     AS|          135|     N527AS|           SEA|                ANC|                 25|            24|             -1|      11|        35|           235|         215|     199|    1448|      254|      5|              320|         259|          -21|       0|        0|               NULL|            NULL|          NULL|         NULL|               NULL|         NULL|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "|IATA_CODE|             AIRPORT|       CITY|STATE|COUNTRY|LATITUDE| LONGITUDE|\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "|      ABE|Lehigh Valley Int...|  Allentown|   PA|    USA|40.65236|  -75.4404|\n",
      "|      ABI|Abilene Regional ...|    Abilene|   TX|    USA|32.41132|  -99.6819|\n",
      "|      ABQ|Albuquerque Inter...|Albuquerque|   NM|    USA|35.04022|-106.60919|\n",
      "|      ABR|Aberdeen Regional...|   Aberdeen|   SD|    USA|45.44906| -98.42183|\n",
      "|      ABY|Southwest Georgia...|     Albany|   GA|    USA|31.53552| -84.19447|\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+--------------------+\n",
      "|IATA_CODE|             AIRLINE|\n",
      "+---------+--------------------+\n",
      "|       UA|United Air Lines ...|\n",
      "|       AA|American Airlines...|\n",
      "|       US|     US Airways Inc.|\n",
      "|       F9|Frontier Airlines...|\n",
      "|       B6|     JetBlue Airways|\n",
      "+---------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "flights_df.show(5)\n",
    "airports_df.show(5)\n",
    "airlines_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d14b37-35a7-48fb-9578-406fe808b6b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Checking for Missing Values (Null Counts)**\n",
    "\n",
    "This cell defines a helper function, `count_nulls(df)`, to count the number of missing values (`null`) in each column of a Spark DataFrame. \n",
    "\n",
    "It then applies this function to each loaded DataFrame (`flights_df`, `airports_df`, and `airlines_df`) and displays the counts of missing values for quick data quality assessment.\n",
    "\n",
    "- **Purpose**: Quickly identify columns with missing data to guide data cleaning and preprocessing steps.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6768124-e0ee-4fcf-911a-b49a98bf2157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T19:30:50.305769Z",
     "iopub.status.busy": "2025-03-13T19:30:50.305538Z",
     "iopub.status.idle": "2025-03-13T19:31:27.818419Z",
     "shell.execute_reply": "2025-03-13T19:31:27.817509Z",
     "shell.execute_reply.started": "2025-03-13T19:30:50.305742Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4559076276b54851859441674ed074fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null counts in flights_df:\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|   0|    0|  0|          0|      0|            0|      14721|             0|                  0|                  0|         86153|          86153|   89047|     89047|             6|      105071|  105071|       0|    92513|  92513|                0|       92513|       105071|       0|        0|            5729195|         4755640|       4755640|      4755640|            4755640|      4755640|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "\n",
      "Null counts in airports_df:\n",
      "+---------+-------+----+-----+-------+--------+---------+\n",
      "|IATA_CODE|AIRPORT|CITY|STATE|COUNTRY|LATITUDE|LONGITUDE|\n",
      "+---------+-------+----+-----+-------+--------+---------+\n",
      "|        0|      0|   0|    0|      0|       3|        3|\n",
      "+---------+-------+----+-----+-------+--------+---------+\n",
      "\n",
      "Null counts in airlines_df:\n",
      "+---------+-------+\n",
      "|IATA_CODE|AIRLINE|\n",
      "+---------+-------+\n",
      "|        0|      0|\n",
      "+---------+-------+"
     ]
    }
   ],
   "source": [
    "#from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Define a helper function to count nulls for each column in a DataFrame\n",
    "def count_nulls(df):\n",
    "    return df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "\n",
    "# Count nulls for each DataFrame and display the results\n",
    "print(\"Null counts in flights_df:\")\n",
    "count_nulls(flights_df).show()\n",
    "\n",
    "print(\"Null counts in airports_df:\")\n",
    "count_nulls(airports_df).show()\n",
    "\n",
    "print(\"Null counts in airlines_df:\")\n",
    "count_nulls(airlines_df).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6befa026-588a-4631-bb75-f98b4bf10ce1",
   "metadata": {},
   "source": [
    "#### Examine the Percentage of Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc800f33-f924-49e2-b4ed-9200ee240598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T04:59:32.463281Z",
     "iopub.status.busy": "2025-03-13T04:59:32.463025Z",
     "iopub.status.idle": "2025-03-13T05:02:04.907857Z",
     "shell.execute_reply": "2025-03-13T05:02:04.906194Z",
     "shell.execute_reply.started": "2025-03-13T04:59:32.463252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758b103268394877811b5eecb36fa1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR: 0 nulls, 0.00%\n",
      "MONTH: 0 nulls, 0.00%\n",
      "DAY: 0 nulls, 0.00%\n",
      "DAY_OF_WEEK: 0 nulls, 0.00%\n",
      "AIRLINE: 0 nulls, 0.00%\n",
      "FLIGHT_NUMBER: 0 nulls, 0.00%\n",
      "TAIL_NUMBER: 14721 nulls, 0.25%\n",
      "ORIGIN_AIRPORT: 0 nulls, 0.00%\n",
      "DESTINATION_AIRPORT: 0 nulls, 0.00%\n",
      "SCHEDULED_DEPARTURE: 0 nulls, 0.00%\n",
      "DEPARTURE_TIME: 86153 nulls, 1.48%\n",
      "DEPARTURE_DELAY: 86153 nulls, 1.48%\n",
      "TAXI_OUT: 89047 nulls, 1.53%\n",
      "WHEELS_OFF: 89047 nulls, 1.53%\n",
      "SCHEDULED_TIME: 6 nulls, 0.00%\n",
      "ELAPSED_TIME: 105071 nulls, 1.81%\n",
      "AIR_TIME: 105071 nulls, 1.81%\n",
      "DISTANCE: 0 nulls, 0.00%\n",
      "WHEELS_ON: 92513 nulls, 1.59%\n",
      "TAXI_IN: 92513 nulls, 1.59%\n",
      "SCHEDULED_ARRIVAL: 0 nulls, 0.00%\n",
      "ARRIVAL_TIME: 92513 nulls, 1.59%\n",
      "ARRIVAL_DELAY: 105071 nulls, 1.81%\n",
      "DIVERTED: 0 nulls, 0.00%\n",
      "CANCELLED: 0 nulls, 0.00%\n",
      "CANCELLATION_REASON: 5729195 nulls, 98.46%\n",
      "AIR_SYSTEM_DELAY: 4755640 nulls, 81.72%\n",
      "SECURITY_DELAY: 4755640 nulls, 81.72%\n",
      "AIRLINE_DELAY: 4755640 nulls, 81.72%\n",
      "LATE_AIRCRAFT_DELAY: 4755640 nulls, 81.72%\n",
      "WEATHER_DELAY: 4755640 nulls, 81.72%"
     ]
    }
   ],
   "source": [
    "total_rows = flights_df.count()\n",
    "null_percent_df = count_nulls(flights_df).withColumn(\n",
    "    \"percentage\", \n",
    "    F.expr(f\"({list(flights_df.columns)[0]} / {total_rows}) * 100\")\n",
    ")\n",
    "# Alternatively, loop through columns:\n",
    "for c in flights_df.columns:\n",
    "    null_count = flights_df.filter(F.col(c).isNull()).count()\n",
    "    print(f\"{c}: {null_count} nulls, {(null_count / total_rows) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f498683-4df9-46ec-9a42-41db452f7a0c",
   "metadata": {},
   "source": [
    "---\n",
    "### Analysis of Missing Values and Imputation Strategy\n",
    "\n",
    "The analysis below summarizes the percentage of missing (`null`) values in each column of the `flights_df` DataFrame:\n",
    "\n",
    "**Key Insights:**\n",
    "\n",
    "- **No missing values (0%)**:  \n",
    "  `YEAR`, `MONTH`, `DAY`, `DAY_OF_WEEK`, `AIRLINE`, `FLIGHT_NUMBER`, `ORIGIN_AIRPORT`, `DESTINATION_AIRPORT`, `SCHEDULED_DEPARTURE`, `DISTANCE`, `SCHEDULED_ARRIVAL`, `DIVERTED`, `CANCELLED`.\n",
    "\n",
    "- **Moderate missing values (approx. 1-2%)**:  \n",
    "  `TAIL_NUMBER (0.25%)`, `DEPARTURE_TIME (1.48%)`, `DEPARTURE_DELAY (1.48%)`, `TAXI_OUT (1.53%)`, `WHEELS_OFF (1.53%)`, `ELAPSED_TIME (1.81%)`, `AIR_TIME (1.81%)`, `WHEELS_ON (1.59%)`, `TAXI_IN (1.59%)`, `ARRIVAL_TIME (1.59%)`, `ARRIVAL_DELAY (1.81%)`.\n",
    "\n",
    "- **Highly missing columns**:  \n",
    "  - `CANCELLATION_REASON (98.46%)`:  \n",
    "    Expected, since this is populated only for canceled flights.  \n",
    "    **Imputation:** Replace nulls with \"Not Cancelled\".\n",
    "  \n",
    "  - Delay-related columns (`AIR_SYSTEM_DELAY`, `SECURITY_DELAY`, `AIRLINE_DELAY`, `LATE_AIRCRAFT_DELAY`, `WEATHER_DELAY`) all at **81.72%** missing:  \n",
    "    These are populated only if delays occur.  \n",
    "    **Imputation:** Replace nulls with `0` (indicating no delay).\n",
    "\n",
    "**Actionable Steps:**\n",
    "\n",
    "- Replace nulls in delay-related columns with `0`.\n",
    "- Replace nulls in `CANCELLATION_REASON` with `\"Not Cancelled\"`.\n",
    "- Re-check null counts afterward to confirm successful imputation.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0309df24-a1b7-4c10-a2e6-91f25ab9991b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T19:33:38.075339Z",
     "iopub.status.busy": "2025-03-13T19:33:38.074996Z",
     "iopub.status.idle": "2025-03-13T19:33:38.380837Z",
     "shell.execute_reply": "2025-03-13T19:33:38.380064Z",
     "shell.execute_reply.started": "2025-03-13T19:33:38.075293Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d97848c84d4bf6be2ee4b66c3abff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# List of delay-related columns to fill with 0\n",
    "delay_columns = [\"AIR_SYSTEM_DELAY\", \"SECURITY_DELAY\", \"AIRLINE_DELAY\", \"LATE_AIRCRAFT_DELAY\", \"WEATHER_DELAY\"]\n",
    "\n",
    "# Fill nulls in delay columns with 0\n",
    "flights_df_cleaned = flights_df.fillna({col: 0 for col in delay_columns})\n",
    "\n",
    "# Fill nulls in CANCELLATION_REASON with \"Not Cancelled\"\n",
    "flights_df_cleaned = flights_df_cleaned.fillna({\"CANCELLATION_REASON\": \"Not Cancelled\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c78a18-1a91-4a24-9cb6-ae4f0ca20502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T19:33:48.329344Z",
     "iopub.status.busy": "2025-03-13T19:33:48.329089Z",
     "iopub.status.idle": "2025-03-13T19:34:25.748250Z",
     "shell.execute_reply": "2025-03-13T19:34:25.747467Z",
     "shell.execute_reply.started": "2025-03-13T19:33:48.329316Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0251548deb42ba8b72613f6b9e6a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, null counts:\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|   0|    0|  0|          0|      0|            0|      14721|             0|                  0|                  0|         86153|          86153|   89047|     89047|             6|      105071|  105071|       0|    92513|  92513|                0|       92513|       105071|       0|        0|                  0|               0|             0|            0|                  0|            0|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+"
     ]
    }
   ],
   "source": [
    "# Define a helper function to count nulls for each column\n",
    "def count_nulls(df):\n",
    "    return df.select([F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "\n",
    "# Show the null counts after cleaning\n",
    "print(\"After cleaning, null counts:\")\n",
    "count_nulls(flights_df_cleaned).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cc0fccb-9921-4eda-a7d6-e5db96940cfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:02:57.848521Z",
     "iopub.status.busy": "2025-03-13T05:02:57.848251Z",
     "iopub.status.idle": "2025-03-13T05:04:54.009160Z",
     "shell.execute_reply": "2025-03-13T05:04:54.008243Z",
     "shell.execute_reply.started": "2025-03-13T05:02:57.848493Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db45e2a5b4fe4b69aeb66d900bd7cd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR: 0 nulls, 0.00%\n",
      "MONTH: 0 nulls, 0.00%\n",
      "DAY: 0 nulls, 0.00%\n",
      "DAY_OF_WEEK: 0 nulls, 0.00%\n",
      "AIRLINE: 0 nulls, 0.00%\n",
      "FLIGHT_NUMBER: 0 nulls, 0.00%\n",
      "TAIL_NUMBER: 14721 nulls, 0.25%\n",
      "ORIGIN_AIRPORT: 0 nulls, 0.00%\n",
      "DESTINATION_AIRPORT: 0 nulls, 0.00%\n",
      "SCHEDULED_DEPARTURE: 0 nulls, 0.00%\n",
      "DEPARTURE_TIME: 86153 nulls, 1.48%\n",
      "DEPARTURE_DELAY: 86153 nulls, 1.48%\n",
      "TAXI_OUT: 89047 nulls, 1.53%\n",
      "WHEELS_OFF: 89047 nulls, 1.53%\n",
      "SCHEDULED_TIME: 6 nulls, 0.00%\n",
      "ELAPSED_TIME: 105071 nulls, 1.81%\n",
      "AIR_TIME: 105071 nulls, 1.81%\n",
      "DISTANCE: 0 nulls, 0.00%\n",
      "WHEELS_ON: 92513 nulls, 1.59%\n",
      "TAXI_IN: 92513 nulls, 1.59%\n",
      "SCHEDULED_ARRIVAL: 0 nulls, 0.00%\n",
      "ARRIVAL_TIME: 92513 nulls, 1.59%\n",
      "ARRIVAL_DELAY: 105071 nulls, 1.81%\n",
      "DIVERTED: 0 nulls, 0.00%\n",
      "CANCELLED: 0 nulls, 0.00%\n",
      "CANCELLATION_REASON: 0 nulls, 0.00%\n",
      "AIR_SYSTEM_DELAY: 0 nulls, 0.00%\n",
      "SECURITY_DELAY: 0 nulls, 0.00%\n",
      "AIRLINE_DELAY: 0 nulls, 0.00%\n",
      "LATE_AIRCRAFT_DELAY: 0 nulls, 0.00%\n",
      "WEATHER_DELAY: 0 nulls, 0.00%"
     ]
    }
   ],
   "source": [
    "total_rows = flights_df_cleaned.count()\n",
    "null_percent_df = count_nulls(flights_df_cleaned).withColumn(\n",
    "    \"percentage\", \n",
    "    F.expr(f\"({list(flights_df_cleaned.columns)[0]} / {total_rows}) * 100\")\n",
    ")\n",
    "# Alternatively, loop through columns:\n",
    "for c in flights_df_cleaned.columns:\n",
    "    null_count = flights_df_cleaned.filter(F.col(c).isNull()).count()\n",
    "    print(f\"{c}: {null_count} nulls, {(null_count / total_rows) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac022221-2bc4-48b9-a908-905e91c7261c",
   "metadata": {},
   "source": [
    "---\n",
    "### Verification of Missing Value Imputation (Post-Cleaning)\n",
    "\n",
    "The output confirms the successful completion of data cleaning:\n",
    "\n",
    "**Successfully Handled Columns (now 0% nulls):**  \n",
    "- **`CANCELLATION_REASON`**: Null values replaced with `\"Not Cancelled\"`.\n",
    "- **Delay-related columns** (`AIR_SYSTEM_DELAY`, `SECURITY_DELAY`, `AIRLINE_DELAY`, `LATE_AIRCRAFT_DELAY`, `WEATHER_DELAY`): Null values replaced with `0`, indicating no delay occurred.\n",
    "\n",
    "**Columns Still Containing Missing Values (low percentages):**  \n",
    "- `TAIL_NUMBER`: 0.25% missing\n",
    "- `DEPARTURE_TIME`, `DEPARTURE_DELAY`: ~1.48% missing\n",
    "- `TAXI_OUT`, `WHEELS_OFF`: ~1.53% missing\n",
    "- `ELAPSED_TIME`, `AIR_TIME`, `ARRIVAL_DELAY`: ~1.81% missing\n",
    "- `WHEELS_ON`, `TAXI_IN`, `ARRIVAL_TIME`: ~1.59% missing\n",
    "\n",
    "These remaining missing values represent a very small proportion of the data. Depending on the significance of these columns in subsequent analyses or modeling, you may either leave them as-is, remove affected rows, or apply additional imputation methods.\n",
    "\n",
    "**Conclusion:**  \n",
    "The primary data-cleaning step addressing major null-value issues has been successfully executed.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892ccd0-6b2e-47d5-ac02-cd08264aadb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T02:09:02.123907Z",
     "iopub.status.busy": "2025-03-13T02:09:02.123656Z",
     "iopub.status.idle": "2025-03-13T02:09:02.190980Z",
     "shell.execute_reply": "2025-03-13T02:09:02.190112Z",
     "shell.execute_reply.started": "2025-03-13T02:09:02.123879Z"
    },
    "tags": []
   },
   "source": [
    "### Summary Statistics and Schema Verification for Cleaned Flights DataFrame\n",
    "\n",
    "This step performs exploratory analysis by generating summary statistics and verifying data types:\n",
    "\n",
    "- **Summary Statistics** (`describe()`):  \n",
    "  Provides count, mean, standard deviation, minimum, and maximum values for numeric columns in `flights_df_cleaned`. Useful for identifying data distributions, potential outliers, and overall data quality.\n",
    "\n",
    "- **Schema Verification** (`printSchema()`):  \n",
    "  Displays the data type of each column, ensuring that the columns have the correct types (e.g., numeric, string, categorical) after cleaning.\n",
    "\n",
    "This ensures the data is properly cleaned, consistent, and ready for subsequent analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f954796-9345-471c-9716-87c67d683672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:05:22.604461Z",
     "iopub.status.busy": "2025-03-13T05:05:22.604103Z",
     "iopub.status.idle": "2025-03-13T05:06:18.146696Z",
     "shell.execute_reply": "2025-03-13T05:06:18.145826Z",
     "shell.execute_reply.started": "2025-03-13T05:05:22.604417Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20c062675074f10ae4608504578e13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------------+-----------------+------------------+-------+------------------+-----------+------------------+-------------------+-------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+--------------------+--------------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+\n",
      "|summary|                YEAR|            MONTH|              DAY|       DAY_OF_WEEK|AIRLINE|     FLIGHT_NUMBER|TAIL_NUMBER|    ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|    DEPARTURE_TIME|   DEPARTURE_DELAY|         TAXI_OUT|        WHEELS_OFF|   SCHEDULED_TIME|      ELAPSED_TIME|          AIR_TIME|         DISTANCE|         WHEELS_ON|           TAXI_IN| SCHEDULED_ARRIVAL|      ARRIVAL_TIME|    ARRIVAL_DELAY|            DIVERTED|           CANCELLED|CANCELLATION_REASON|  AIR_SYSTEM_DELAY|      SECURITY_DELAY|     AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|     WEATHER_DELAY|\n",
      "+-------+--------------------+-----------------+-----------------+------------------+-------+------------------+-----------+------------------+-------------------+-------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+--------------------+--------------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+\n",
      "|  count|             5819079|          5819079|          5819079|           5819079|5819079|           5819079|    5804358|           5819079|            5819079|            5819079|           5732926|           5732926|          5730032|           5730032|          5819073|           5714008|           5714008|          5819079|           5726566|           5726566|           5819079|           5726566|          5714008|             5819079|             5819079|            5819079|           5819079|             5819079|           5819079|            5819079|           5819079|\n",
      "|   mean|              2015.0|6.524085168804204|15.70459397440729|3.9269411877721545|   NULL|2173.0927423394664|       NULL|12666.699787109315| 12666.853627883538| 1329.6024700816056|1335.2044390595659| 9.370158275198389|16.07166225249702|1357.1708412797695|141.6858915500802|137.00618917579393|113.51162809012519|822.3564947305235|1471.4686087613413|7.4349708010001105|1493.8082485218022|1476.4911879126164|4.407057357987598|0.002609863175942...|0.015446430612129514|               NULL|2.4635792021383454|0.013917150806854487|  3.46669223772353|  4.289670410042551|0.5327703920156437|\n",
      "| stddev|1.956196210050383...|3.405136828055511|8.783425069807082|1.9888450134329616|   NULL|1757.0639987866114|       NULL|1526.7134944584895| 1526.6619201888464| 483.75182087310895| 496.4232601194165|37.080942496786925|8.895574065449809| 498.0093562214895|75.21058230600212| 74.21107169827957| 72.23082162028545|607.7842873170472| 522.1879449700472| 5.638547687322198|  507.164695593694|  526.319737212267|39.27129709388634|0.051020116008059946| 0.12332007544158788|               NULL|13.055844805569814|   0.916786451855813|21.854996035208746| 20.574213062961395|  8.80746525667673|\n",
      "|    min|                2015|                1|                1|                 1|     AA|                 1|      7819A|             10135|              10135|                  1|                 1|               -82|                1|                 1|               18|                14|                 7|               21|                 1|                 1|                 1|                 1|              -87|                   0|                   0|                  A|                 0|                   0|                 0|                  0|                 0|\n",
      "|    max|                2015|               12|               31|                 7|     WN|              9855|     N9EAMQ|               YUM|                YUM|               2359|              2400|              1988|              225|              2400|              718|               766|               690|             4983|              2400|               248|              2400|              2400|             1971|                   1|                   1|      Not Cancelled|              1134|                 573|              1971|               1331|              1211|\n",
      "+-------+--------------------+-----------------+-----------------+------------------+-------+------------------+-----------+------------------+-------------------+-------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+--------------------+--------------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+"
     ]
    }
   ],
   "source": [
    "# Generate summary statistics for the cleaned flights DataFrame.\n",
    "flights_df_cleaned.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bcb81fd-bee4-4509-a9af-c0b193380056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:07:52.573298Z",
     "iopub.status.busy": "2025-03-13T05:07:52.573047Z",
     "iopub.status.idle": "2025-03-13T05:07:52.661159Z",
     "shell.execute_reply": "2025-03-13T05:07:52.660563Z",
     "shell.execute_reply.started": "2025-03-13T05:07:52.573268Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c798edc9516043c7b040e8ac032aee7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DEPARTURE_TIME: integer (nullable = true)\n",
      " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- ARRIVAL_TIME: integer (nullable = true)\n",
      " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_REASON: string (nullable = false)\n",
      " |-- AIR_SYSTEM_DELAY: integer (nullable = false)\n",
      " |-- SECURITY_DELAY: integer (nullable = false)\n",
      " |-- AIRLINE_DELAY: integer (nullable = false)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = false)\n",
      " |-- WEATHER_DELAY: integer (nullable = false)"
     ]
    }
   ],
   "source": [
    "# list the schema to verify the types\n",
    "flights_df_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4a740-78d6-47a9-a13e-5637096d5576",
   "metadata": {},
   "source": [
    "---\n",
    "### Visualization of Delay Distributions\n",
    "\n",
    "This step creates visual summaries (histograms) of flight delay metrics using a sampled subset (`1%`) of the cleaned dataset to maintain computational efficiency:\n",
    "\n",
    "- **Departure Delay Histogram (`DEPARTURE_DELAY`):**\n",
    "  - Illustrates the frequency and distribution of departure delays (in minutes).\n",
    "\n",
    "- **Arrival Delay Histogram (`ARRIVAL_DELAY`):**\n",
    "  - Displays the distribution of arrival delays, highlighting typical delay patterns.\n",
    "\n",
    "- **Airline Delay Histogram (`AIRLINE_DELAY`):**\n",
    "  - Shows delays attributed specifically to airlines, providing insights into airline-related performance.\n",
    "\n",
    "Each plot is saved as an image (`departure_delay.png`, `arrival_delay.png`, `airline_delay.png`) for easy inclusion in reports or presentations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b8102fb-b384-4977-9a30-bb52b4f3da2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T19:34:59.164468Z",
     "iopub.status.busy": "2025-03-13T19:34:59.164227Z",
     "iopub.status.idle": "2025-03-13T19:35:18.532378Z",
     "shell.execute_reply": "2025-03-13T19:35:18.531290Z",
     "shell.execute_reply.started": "2025-03-13T19:34:59.164441Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbb125f3b0242a1aba8378f7d316933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Since the dataset may be large, take a sample for plotting\n",
    "sample_fraction = 0.01  # Adjust this fraction as needed\n",
    "sample_df = flights_df_cleaned.sample(withReplacement=False, fraction=sample_fraction, seed=42).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "190f5e97-1232-4bdd-b017-311cf0bb4c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T19:35:23.489522Z",
     "iopub.status.busy": "2025-03-13T19:35:23.489268Z",
     "iopub.status.idle": "2025-03-13T19:35:24.265328Z",
     "shell.execute_reply": "2025-03-13T19:35:24.264650Z",
     "shell.execute_reply.started": "2025-03-13T19:35:23.489493Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77550d06da6047af9cba63c36455c10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as departure_delay.png"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(sample_df['DEPARTURE_DELAY'].dropna(), bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Distribution of DEPARTURE_DELAY\")\n",
    "plt.xlabel(\"Departure Delay (minutes)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"departure_delay.png\")\n",
    "print(\"Plot saved as departure_delay.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20347860-d5c4-4d52-b9f3-69b4e0ca65a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T19:36:34.844571Z",
     "iopub.status.busy": "2025-03-13T19:36:34.844342Z",
     "iopub.status.idle": "2025-03-13T19:36:35.136182Z",
     "shell.execute_reply": "2025-03-13T19:36:35.134462Z",
     "shell.execute_reply.started": "2025-03-13T19:36:34.844546Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bed44b5cb04cb5bb8f13a51a0c90d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as arrival_delay.png"
     ]
    }
   ],
   "source": [
    "# Plot a histogram of ARRIVAL_DELAY\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(sample_df['ARRIVAL_DELAY'].dropna(), bins=50, color='lightgreen', edgecolor='black')\n",
    "plt.title(\"Distribution of ARRIVAL_DELAY\")\n",
    "plt.xlabel(\"Arrival Delay (minutes)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"arrival_delay.png\")  # Save the plot to a file\n",
    "print(\"Plot saved as arrival_delay.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d5a1f39-bf76-48f3-b935-e98a977cc3fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T19:36:38.135233Z",
     "iopub.status.busy": "2025-03-13T19:36:38.134962Z",
     "iopub.status.idle": "2025-03-13T19:36:38.404523Z",
     "shell.execute_reply": "2025-03-13T19:36:38.403846Z",
     "shell.execute_reply.started": "2025-03-13T19:36:38.135204Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff3a168b1eb457fb321628804e8fe46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as airline_delay.png"
     ]
    }
   ],
   "source": [
    "# Plot a histogram for one of the delay-related features, e.g., AIRLINE_DELAY\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(sample_df['AIRLINE_DELAY'].dropna(), bins=50, color='salmon', edgecolor='black')\n",
    "plt.title(\"Distribution of AIRLINE_DELAY\")\n",
    "plt.xlabel(\"Airline Delay (minutes)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"airline_delay.png\")  # Save the plot to a file\n",
    "print(\"Plot saved as airline_delay.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e6231-66d1-46e9-ba71-b20fbc5f904d",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Uploading Delay Plots to Amazon S3\n",
    "\n",
    "This step uploads the generated delay distribution plots to Amazon S3, making them accessible for sharing or future reference:\n",
    "\n",
    "- **Departure Delay Plot (`departure_delay.png`)**\n",
    "  - Uploaded to: `s3://final-csc555/plots/departure_delay.png`\n",
    "\n",
    "- **Arrival Delay Plot (`arrival_delay.png`)**\n",
    "  - Uploaded to: `s3://final-csc555/plots/arrival_delay.png`\n",
    "\n",
    "- **Airline Delay Plot (`airline_delay.png`)**\n",
    "  - Uploaded to: `s3://final-csc555/plots/airline_delay.png`\n",
    "\n",
    "These visualizations are now securely stored in S3 and available for further analysis or reporting purposes.\n",
    "\n",
    "> **Note:**  \n",
    "> *Ensure that the keys (destination paths) are correctly set to avoid overwriting files. In your provided code, ensure you correct the destination key for the `departure_delay.png` to:*\n",
    "\n",
    "```python\n",
    "s3.upload_file(\"departure_delay.png\", bucket_name, s3_key_departure)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73c050e5-39b8-4b0d-bcf3-bfeb9f62cd24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T19:38:16.829857Z",
     "iopub.status.busy": "2025-03-13T19:38:16.829604Z",
     "iopub.status.idle": "2025-03-13T19:38:17.605974Z",
     "shell.execute_reply": "2025-03-13T19:38:17.605202Z",
     "shell.execute_reply.started": "2025-03-13T19:38:16.829831Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa57985fed36486789d4670bedd9d170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "departure_delay plot uploaded to s3://final-csc555/plots/arrival_delay.png\n",
      "arrival_delay plot uploaded to s3://final-csc555/plots/arrival_delay.png\n",
      "airline_delay plot uploaded to s3://final-csc555/plots/airline_delay.png"
     ]
    }
   ],
   "source": [
    "# Create an S3 client (this uses the credentials from your EMR environment)\n",
    "s3 = boto3.client('s3', region_name='us-east-1')\n",
    "bucket_name = \"final-csc555\"\n",
    "\n",
    "# Define S3 keys (destination paths) for each plot\n",
    "s3_key_departure = \"plots/departure_delay.png\"\n",
    "s3_key_arrival = \"plots/arrival_delay.png\"\n",
    "s3_key_airline = \"plots/airline_delay.png\"\n",
    "\n",
    "# Upload the departure_delay plot\n",
    "s3.upload_file(\"departure_delay.png\", bucket_name, s3_key_arrival)\n",
    "print(f\"departure_delay plot uploaded to s3://{bucket_name}/{s3_key_arrival}\")\n",
    "\n",
    "# Upload the arrival_delay plot\n",
    "s3.upload_file(\"arrival_delay.png\", bucket_name, s3_key_arrival)\n",
    "print(f\"arrival_delay plot uploaded to s3://{bucket_name}/{s3_key_arrival}\")\n",
    "\n",
    "# Upload the airline_delay plot\n",
    "s3.upload_file(\"airline_delay.png\", bucket_name, s3_key_airline)\n",
    "print(f\"airline_delay plot uploaded to s3://{bucket_name}/{s3_key_airline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffd0228-02df-449f-b0e0-1efd77d9f5f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Correlation Analysis of Delay Features\n",
    "\n",
    "This step calculates pairwise correlations among selected numeric features to understand their relationships:\n",
    "\n",
    "**Individual correlations computed:**\n",
    "\n",
    "- **Departure Delay vs Arrival Delay**:  \n",
    "  Measures how strongly departure delays are associated with arrival delays.\n",
    "\n",
    "- **Departure Delay vs Elapsed Time**:  \n",
    "  Measures the relationship between departure delays and total elapsed flight time.\n",
    "\n",
    "**Correlation Matrix for Selected Columns** (`DEPARTURE_DELAY`, `ARRIVAL_DELAY`, `ELAPSED_TIME`, `AIRLINE_DELAY`):\n",
    "\n",
    "- Provides an overview of how strongly each delay-related feature correlates with the others.\n",
    "- Useful for identifying features with strong relationships, aiding feature selection in modeling.\n",
    "\n",
    "High correlation values (close to ±1) indicate strong linear relationships, which can inform modeling strategies or highlight potential issues such as multicollinearity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07839a37-e7bf-45f6-8b9d-7d23043a1dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:15:15.853139Z",
     "iopub.status.busy": "2025-03-13T05:15:15.852850Z",
     "iopub.status.idle": "2025-03-13T05:15:47.353362Z",
     "shell.execute_reply": "2025-03-13T05:15:47.352432Z",
     "shell.execute_reply.started": "2025-03-13T05:15:15.853099Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15bf89b2d7b4d08a6a80d4068e3ba08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between DEPARTURE_DELAY and ARRIVAL_DELAY: 0.9379\n",
      "Correlation between DEPARTURE_DELAY and ELAPSED_TIME: 0.0327"
     ]
    }
   ],
   "source": [
    "# Let's compute correlations between a few numeric columns.\n",
    "# For example: DEPARTURE_DELAY vs ARRIVAL_DELAY, and DEPARTURE_DELAY vs ELAPSED_TIME\n",
    "corr_departure_arrival = flights_df_cleaned.stat.corr(\"DEPARTURE_DELAY\", \"ARRIVAL_DELAY\")\n",
    "corr_departure_elapsed = flights_df_cleaned.stat.corr(\"DEPARTURE_DELAY\", \"ELAPSED_TIME\")\n",
    "\n",
    "print(\"Correlation between DEPARTURE_DELAY and ARRIVAL_DELAY: {:.4f}\".format(corr_departure_arrival))\n",
    "print(\"Correlation between DEPARTURE_DELAY and ELAPSED_TIME: {:.4f}\".format(corr_departure_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abfa3c64-556a-4106-ab66-1d53ad49e652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:16:23.698042Z",
     "iopub.status.busy": "2025-03-13T05:16:23.697804Z",
     "iopub.status.idle": "2025-03-13T05:18:05.578251Z",
     "shell.execute_reply": "2025-03-13T05:18:05.577138Z",
     "shell.execute_reply.started": "2025-03-13T05:16:23.698014Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d442388e148341cfa03bf202ff3b1239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "DEPARTURE_DELAY: {'DEPARTURE_DELAY': 1.0, 'ARRIVAL_DELAY': 0.9379, 'ELAPSED_TIME': 0.0327, 'AIRLINE_DELAY': 0.6537}\n",
      "ARRIVAL_DELAY: {'DEPARTURE_DELAY': 0.9379, 'ARRIVAL_DELAY': 1.0, 'ELAPSED_TIME': 0.0319, 'AIRLINE_DELAY': 0.6276}\n",
      "ELAPSED_TIME: {'DEPARTURE_DELAY': 0.0327, 'ARRIVAL_DELAY': 0.0319, 'ELAPSED_TIME': 1.0, 'AIRLINE_DELAY': 0.0253}\n",
      "AIRLINE_DELAY: {'DEPARTURE_DELAY': 0.6537, 'ARRIVAL_DELAY': 0.6276, 'ELAPSED_TIME': 0.0253, 'AIRLINE_DELAY': 1.0}"
     ]
    }
   ],
   "source": [
    "# If needed, you can create a correlation matrix for selected numeric columns\n",
    "numeric_cols = [\"DEPARTURE_DELAY\", \"ARRIVAL_DELAY\", \"ELAPSED_TIME\", \"AIRLINE_DELAY\"]\n",
    "corr_dict = {}\n",
    "for col1 in numeric_cols:\n",
    "    corr_dict[col1] = {}\n",
    "    for col2 in numeric_cols:\n",
    "        corr_val = flights_df_cleaned.stat.corr(col1, col2)\n",
    "        corr_dict[col1][col2] = round(corr_val, 4)\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "for col, corr_vals in corr_dict.items():\n",
    "    print(f\"{col}: {corr_vals}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa4573e-efb0-4311-83bd-48efc200bf10",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Feature Engineering: Extracting and Creating Time-based Features\n",
    "\n",
    "This step extracts new meaningful features from the existing `SCHEDULED_DEPARTURE` column (assumed to be in HHMM format):\n",
    "\n",
    "**Newly created features:**\n",
    "\n",
    "- **`departure_hour`**: Hour of scheduled departure extracted from HHMM format.\n",
    "- **`departure_minute`**: Minute component of scheduled departure.\n",
    "- **`early_morning`**: A binary indicator (1 if the flight departs before 6:00 AM, 0 otherwise).\n",
    "\n",
    "**Purpose of these features:**\n",
    "\n",
    "- Capturing the time-related patterns in flight delays (e.g., early-morning flights might have different delay characteristics).\n",
    "- Providing additional insights for predictive modeling and analysis.\n",
    "\n",
    "Verification steps included ensure the correctness and accuracy of these new features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6749e8a-e22f-4df2-a341-cd2a2619d0c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:18:22.858017Z",
     "iopub.status.busy": "2025-03-13T05:18:22.857765Z",
     "iopub.status.idle": "2025-03-13T05:18:23.655233Z",
     "shell.execute_reply": "2025-03-13T05:18:23.654404Z",
     "shell.execute_reply.started": "2025-03-13T05:18:22.857982Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee87f266c88d49d1ab95cc702e347f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+----------------+\n",
      "|SCHEDULED_DEPARTURE|departure_hour|departure_minute|\n",
      "+-------------------+--------------+----------------+\n",
      "|                  5|             0|               5|\n",
      "|                 10|             0|              10|\n",
      "|                 20|             0|              20|\n",
      "|                 20|             0|              20|\n",
      "|                 25|             0|              25|\n",
      "|                 25|             0|              25|\n",
      "|                 25|             0|              25|\n",
      "|                 30|             0|              30|\n",
      "|                 30|             0|              30|\n",
      "|                 30|             0|              30|\n",
      "|                 30|             0|              30|\n",
      "|                 35|             0|              35|\n",
      "|                 35|             0|              35|\n",
      "|                 40|             0|              40|\n",
      "|                 40|             0|              40|\n",
      "|                 45|             0|              45|\n",
      "|                 45|             0|              45|\n",
      "|                 48|             0|              48|\n",
      "|                 50|             0|              50|\n",
      "|                 50|             0|              50|\n",
      "|                 55|             0|              55|\n",
      "|                100|             1|               0|\n",
      "|                103|             1|               3|\n",
      "|                105|             1|               5|\n",
      "|                105|             1|               5|\n",
      "|                115|             1|              15|\n",
      "|                115|             1|              15|\n",
      "|                115|             1|              15|\n",
      "|                120|             1|              20|\n",
      "|                120|             1|              20|\n",
      "|                125|             1|              25|\n",
      "|                127|             1|              27|\n",
      "|                135|             1|              35|\n",
      "|                140|             1|              40|\n",
      "|                144|             1|              44|\n",
      "|                145|             1|              45|\n",
      "|                152|             1|              52|\n",
      "|                154|             1|              54|\n",
      "|                155|             1|              55|\n",
      "|                155|             1|              55|\n",
      "|                155|             1|              55|\n",
      "|                159|             1|              59|\n",
      "|                200|             2|               0|\n",
      "|                200|             2|               0|\n",
      "|                200|             2|               0|\n",
      "|                206|             2|               6|\n",
      "|                220|             2|              20|\n",
      "|                220|             2|              20|\n",
      "|                255|             2|              55|\n",
      "|                259|             2|              59|\n",
      "+-------------------+--------------+----------------+\n",
      "only showing top 50 rows"
     ]
    }
   ],
   "source": [
    "# Assume SCHEDULED_DEPARTURE is in HHMM format (e.g., 520 means 5:20 AM).\n",
    "# Create new features: departure_hour and departure_minute.\n",
    "# If SCHEDULED_DEPARTURE is stored as an integer, we can perform integer division and modulo.\n",
    "\n",
    "flights_df_fe = flights_df_cleaned.withColumn(\"departure_hour\", F.floor(F.col(\"SCHEDULED_DEPARTURE\")/100)) \\\n",
    "                                  .withColumn(\"departure_minute\", F.col(\"SCHEDULED_DEPARTURE\") % 100)\n",
    "\n",
    "# Check the newly created features\n",
    "flights_df_fe.select(\"SCHEDULED_DEPARTURE\", \"departure_hour\", \"departure_minute\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92a35a78-d2d1-4c1a-9e6b-3d944d492f12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:18:27.843685Z",
     "iopub.status.busy": "2025-03-13T05:18:27.843396Z",
     "iopub.status.idle": "2025-03-13T05:18:28.629912Z",
     "shell.execute_reply": "2025-03-13T05:18:28.629085Z",
     "shell.execute_reply.started": "2025-03-13T05:18:27.843654Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b116f33be5d4c289ed490daacb436fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+-------------+\n",
      "|departure_hour|departure_minute|early_morning|\n",
      "+--------------+----------------+-------------+\n",
      "|             0|               5|            1|\n",
      "|             0|              10|            1|\n",
      "|             0|              20|            1|\n",
      "|             0|              20|            1|\n",
      "|             0|              25|            1|\n",
      "|             0|              25|            1|\n",
      "|             0|              25|            1|\n",
      "|             0|              30|            1|\n",
      "|             0|              30|            1|\n",
      "|             0|              30|            1|\n",
      "|             0|              30|            1|\n",
      "|             0|              35|            1|\n",
      "|             0|              35|            1|\n",
      "|             0|              40|            1|\n",
      "|             0|              40|            1|\n",
      "|             0|              45|            1|\n",
      "|             0|              45|            1|\n",
      "|             0|              48|            1|\n",
      "|             0|              50|            1|\n",
      "|             0|              50|            1|\n",
      "|             0|              55|            1|\n",
      "|             1|               0|            1|\n",
      "|             1|               3|            1|\n",
      "|             1|               5|            1|\n",
      "|             1|               5|            1|\n",
      "|             1|              15|            1|\n",
      "|             1|              15|            1|\n",
      "|             1|              15|            1|\n",
      "|             1|              20|            1|\n",
      "|             1|              20|            1|\n",
      "|             1|              25|            1|\n",
      "|             1|              27|            1|\n",
      "|             1|              35|            1|\n",
      "|             1|              40|            1|\n",
      "|             1|              44|            1|\n",
      "|             1|              45|            1|\n",
      "|             1|              52|            1|\n",
      "|             1|              54|            1|\n",
      "|             1|              55|            1|\n",
      "|             1|              55|            1|\n",
      "|             1|              55|            1|\n",
      "|             1|              59|            1|\n",
      "|             2|               0|            1|\n",
      "|             2|               0|            1|\n",
      "|             2|               0|            1|\n",
      "|             2|               6|            1|\n",
      "|             2|              20|            1|\n",
      "|             2|              20|            1|\n",
      "|             2|              55|            1|\n",
      "|             2|              59|            1|\n",
      "+--------------+----------------+-------------+\n",
      "only showing top 50 rows"
     ]
    }
   ],
   "source": [
    "# We might also create other features such as:\n",
    "# - A binary flag for early morning flights (e.g., departure_hour < 6)\n",
    "# - Combined features (e.g., a feature that is the sum of various delay components)\n",
    "\n",
    "flights_df_fe = flights_df_fe.withColumn(\"early_morning\", F.when(F.col(\"departure_hour\") < 6, 1).otherwise(0))\n",
    "\n",
    "# Show a few rows to verify the new features\n",
    "flights_df_fe.select(\"departure_hour\", \"departure_minute\", \"early_morning\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "049acc5c-5013-40e3-b280-e8351d7c77b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:18:32.932991Z",
     "iopub.status.busy": "2025-03-13T05:18:32.932720Z",
     "iopub.status.idle": "2025-03-13T05:18:33.724013Z",
     "shell.execute_reply": "2025-03-13T05:18:33.723139Z",
     "shell.execute_reply.started": "2025-03-13T05:18:32.932962Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec1515d4b0d446c9c4ab1fdb5ee0695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+--------------+----------------+-------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|departure_hour|departure_minute|early_morning|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+--------------+----------------+-------------+\n",
      "|2015|    1|  1|          4|     AS|           98|     N407AS|           ANC|                SEA|                  5|          2354|            -11|      21|        15|           205|         194|     169|    1448|      404|      4|              430|         408|          -22|       0|        0|      Not Cancelled|               0|             0|            0|                  0|            0|             0|               5|            1|\n",
      "|2015|    1|  1|          4|     AA|         2336|     N3KUAA|           LAX|                PBI|                 10|             2|             -8|      12|        14|           280|         279|     263|    2330|      737|      4|              750|         741|           -9|       0|        0|      Not Cancelled|               0|             0|            0|                  0|            0|             0|              10|            1|\n",
      "|2015|    1|  1|          4|     US|          840|     N171US|           SFO|                CLT|                 20|            18|             -2|      16|        34|           286|         293|     266|    2296|      800|     11|              806|         811|            5|       0|        0|      Not Cancelled|               0|             0|            0|                  0|            0|             0|              20|            1|\n",
      "|2015|    1|  1|          4|     AA|          258|     N3HYAA|           LAX|                MIA|                 20|            15|             -5|      15|        30|           285|         281|     258|    2342|      748|      8|              805|         756|           -9|       0|        0|      Not Cancelled|               0|             0|            0|                  0|            0|             0|              20|            1|\n",
      "|2015|    1|  1|          4|     AS|          135|     N527AS|           SEA|                ANC|                 25|            24|             -1|      11|        35|           235|         215|     199|    1448|      254|      5|              320|         259|          -21|       0|        0|      Not Cancelled|               0|             0|            0|                  0|            0|             0|              25|            1|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+--------------+----------------+-------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "flights_df_fe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83896eff-e978-403f-8634-53e87ef23adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:18:47.947617Z",
     "iopub.status.busy": "2025-03-13T05:18:47.947350Z",
     "iopub.status.idle": "2025-03-13T05:18:48.017017Z",
     "shell.execute_reply": "2025-03-13T05:18:48.015362Z",
     "shell.execute_reply.started": "2025-03-13T05:18:47.947587Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3fd7f5d3a64494a1fa7c5eb008972d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DEPARTURE_TIME: integer (nullable = true)\n",
      " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
      " |-- TAXI_OUT: integer (nullable = true)\n",
      " |-- WHEELS_OFF: integer (nullable = true)\n",
      " |-- SCHEDULED_TIME: integer (nullable = true)\n",
      " |-- ELAPSED_TIME: integer (nullable = true)\n",
      " |-- AIR_TIME: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- WHEELS_ON: integer (nullable = true)\n",
      " |-- TAXI_IN: integer (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
      " |-- ARRIVAL_TIME: integer (nullable = true)\n",
      " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
      " |-- DIVERTED: integer (nullable = true)\n",
      " |-- CANCELLED: integer (nullable = true)\n",
      " |-- CANCELLATION_REASON: string (nullable = false)\n",
      " |-- AIR_SYSTEM_DELAY: integer (nullable = false)\n",
      " |-- SECURITY_DELAY: integer (nullable = false)\n",
      " |-- AIRLINE_DELAY: integer (nullable = false)\n",
      " |-- LATE_AIRCRAFT_DELAY: integer (nullable = false)\n",
      " |-- WEATHER_DELAY: integer (nullable = false)\n",
      " |-- departure_hour: long (nullable = true)\n",
      " |-- departure_minute: integer (nullable = true)\n",
      " |-- early_morning: integer (nullable = false)"
     ]
    }
   ],
   "source": [
    "flights_df_fe.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac8588-d6c6-4ef6-8531-32f264646ce5",
   "metadata": {},
   "source": [
    "---\n",
    "### Selecting Relevant Features and Removing Unnecessary Columns\n",
    "\n",
    "This step finalizes the dataset for predictive modeling by removing columns that:\n",
    "\n",
    "- **Could cause data leakage** (e.g., actual delays, operational timings available only after departure).\n",
    "- **Contain duplicate or redundant information** (e.g., unique identifiers, dates without predictive relevance).\n",
    "\n",
    "**Dropped columns include:**  \n",
    "- Identifiers and dates: `YEAR`, `DAY`, `TAIL_NUMBER`  \n",
    "- Actual operational times and delays: `DEPARTURE_TIME`, `DEPARTURE_DELAY`, `TAXI_OUT`, `WHEELS_OFF`, `ELAPSED_TIME`, `AIR_TIME`, `WHEELS_ON`, `TAXI_IN`, `ARRIVAL_TIME`, `ARRIVAL_DELAY`  \n",
    "- Post-flight or operational status columns: `DIVERTED`, `CANCELLED`, `CANCELLATION_REASON`, various delay-specific columns  \n",
    "- Minor details not predictive of delays: `departure_minute`\n",
    "\n",
    "The resulting `final_transformed_df` retains columns containing useful pre-flight information, suitable for predictive modeling of flight delays.\n",
    "\n",
    "The schema and a sample of the transformed data are displayed to confirm correctness.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f8cddd5-11dc-4d6a-9c48-24bc36e10e0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:18:52.627840Z",
     "iopub.status.busy": "2025-03-13T05:18:52.627594Z",
     "iopub.status.idle": "2025-03-13T05:18:53.418661Z",
     "shell.execute_reply": "2025-03-13T05:18:53.417837Z",
     "shell.execute_reply.started": "2025-03-13T05:18:52.627810Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7fd7de8c6c4131ab5bcb57c3f2852b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------+-------------+--------------+-------------------+-------------------+--------+--------------+-------------+\n",
      "|MONTH|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DISTANCE|departure_hour|early_morning|\n",
      "+-----+-----------+-------+-------------+--------------+-------------------+-------------------+--------+--------------+-------------+\n",
      "|1    |4          |AS     |98           |ANC           |SEA                |5                  |1448    |0             |1            |\n",
      "|1    |4          |AA     |2336         |LAX           |PBI                |10                 |2330    |0             |1            |\n",
      "|1    |4          |US     |840          |SFO           |CLT                |20                 |2296    |0             |1            |\n",
      "|1    |4          |AA     |258          |LAX           |MIA                |20                 |2342    |0             |1            |\n",
      "|1    |4          |AS     |135          |SEA           |ANC                |25                 |1448    |0             |1            |\n",
      "+-----+-----------+-------+-------------+--------------+-------------------+-------------------+--------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- departure_hour: long (nullable = true)\n",
      " |-- early_morning: integer (nullable = false)"
     ]
    }
   ],
   "source": [
    "# Define a list of columns to drop from your feature-engineered DataFrame.\n",
    "# Adjust this list based on your project needs.\n",
    "cols_to_drop = [\n",
    "    \"YEAR\", \"DAY\", \"TAIL_NUMBER\", \"DEPARTURE_TIME\", \"DEPARTURE_DELAY\",\n",
    "    \"TAXI_OUT\", \"WHEELS_OFF\", \"SCHEDULED_TIME\", \"ELAPSED_TIME\", \"AIR_TIME\",\n",
    "    \"WHEELS_ON\", \"TAXI_IN\", \"SCHEDULED_ARRIVAL\", \"ARRIVAL_TIME\", \"ARRIVAL_DELAY\",\n",
    "    \"DIVERTED\", \"CANCELLED\", \"CANCELLATION_REASON\", \"AIR_SYSTEM_DELAY\", \n",
    "    \"SECURITY_DELAY\", \"AIRLINE_DELAY\", \"LATE_AIRCRAFT_DELAY\", \"WEATHER_DELAY\",\n",
    "    \"departure_minute\"  # you may decide to drop minute if not needed\n",
    "]\n",
    "\n",
    "# Create a final transformed DataFrame by dropping the unnecessary columns.\n",
    "final_transformed_df = flights_df_fe.drop(*cols_to_drop)\n",
    "\n",
    "# Display the final DataFrame to verify the changes.\n",
    "final_transformed_df.show(5, truncate=False)\n",
    "final_transformed_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f67ecc-06a4-4bb8-a7b7-7e0a2c5d9198",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Enrichment: Adding Airline and Airport Information  \n",
    "\n",
    "This step enriches the original dataset by adding descriptive information from external datasets (`airlines_df` and `airports_df`). The final enriched DataFrame (`enriched_df`) contains detailed context about airlines and airports, enhancing its usefulness for modeling and analysis.\n",
    "\n",
    "**Enriched Information includes:**  \n",
    "\n",
    "- **Airline details**:\n",
    "  - Airline full name (`AIRLINE` → `AIRLINE_FULL_NAME`).\n",
    "\n",
    "- **Origin Airport details**:\n",
    "  - Airport name (`ORIGIN_AIRPORT`)\n",
    "  - City (`ORIGIN_CITY`)\n",
    "  - State (`ORIGIN_STATE`)\n",
    "\n",
    "- **Destination Airport details**:\n",
    "  - Airport name (`DESTINATION_AIRPORT`)\n",
    "  - City (`DESTINATION_CITY`)\n",
    "  - State (`DESTINATION_STATE`)\n",
    "\n",
    "These enrichments add meaningful context to the original flight data, potentially improving predictive accuracy and facilitating deeper insights in further analyses or modeling. \n",
    "\n",
    "The enriched data schema and sample records are verified to ensure the correctness of the joins.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b96e95d3-25a5-4284-bb51-4d0423a3d15e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:19:00.532811Z",
     "iopub.status.busy": "2025-03-13T05:19:00.532504Z",
     "iopub.status.idle": "2025-03-13T05:19:02.895606Z",
     "shell.execute_reply": "2025-03-13T05:19:02.893892Z",
     "shell.execute_reply.started": "2025-03-13T05:19:00.532780Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472683e30bac4d32b1de64530f5b5177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------+-------------+--------------+-------------------+-------------------+--------+--------------+-------------+----------------------+-------------------------------------------+-------------+------------+-------------------------------------------+----------------+-----------------+\n",
      "|MONTH|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DISTANCE|departure_hour|early_morning|AIRLINE_FULL_NAME     |ORIGIN_AIRPORT_FULL                        |ORIGIN_CITY  |ORIGIN_STATE|DESTINATION_AIRPORT_FULL                   |DESTINATION_CITY|DESTINATION_STATE|\n",
      "+-----+-----------+-------+-------------+--------------+-------------------+-------------------+--------+--------------+-------------+----------------------+-------------------------------------------+-------------+------------+-------------------------------------------+----------------+-----------------+\n",
      "|1    |4          |AS     |98           |ANC           |SEA                |5                  |1448    |0             |1            |Alaska Airlines Inc.  |Ted Stevens Anchorage International Airport|Anchorage    |AK          |Seattle-Tacoma International Airport       |Seattle         |WA               |\n",
      "|1    |4          |AA     |2336         |LAX           |PBI                |10                 |2330    |0             |1            |American Airlines Inc.|Los Angeles International Airport          |Los Angeles  |CA          |Palm Beach International Airport           |West Palm Beach |FL               |\n",
      "|1    |4          |US     |840          |SFO           |CLT                |20                 |2296    |0             |1            |US Airways Inc.       |San Francisco International Airport        |San Francisco|CA          |Charlotte Douglas International Airport    |Charlotte       |NC               |\n",
      "|1    |4          |AA     |258          |LAX           |MIA                |20                 |2342    |0             |1            |American Airlines Inc.|Los Angeles International Airport          |Los Angeles  |CA          |Miami International Airport                |Miami           |FL               |\n",
      "|1    |4          |AS     |135          |SEA           |ANC                |25                 |1448    |0             |1            |Alaska Airlines Inc.  |Seattle-Tacoma International Airport       |Seattle      |WA          |Ted Stevens Anchorage International Airport|Anchorage       |AK               |\n",
      "+-----+-----------+-------+-------------+--------------+-------------------+-------------------+--------+--------------+-------------+----------------------+-------------------------------------------+-------------+------------+-------------------------------------------+----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- departure_hour: long (nullable = true)\n",
      " |-- early_morning: integer (nullable = false)\n",
      " |-- AIRLINE_FULL_NAME: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT_FULL: string (nullable = true)\n",
      " |-- ORIGIN_CITY: string (nullable = true)\n",
      " |-- ORIGIN_STATE: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT_FULL: string (nullable = true)\n",
      " |-- DESTINATION_CITY: string (nullable = true)\n",
      " |-- DESTINATION_STATE: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# final_transformed_df is the final cleaned dataset with columns:\n",
    "# MONTH, DAY_OF_WEEK, AIRLINE, FLIGHT_NUMBER, ORIGIN_AIRPORT, DESTINATION_AIRPORT,\n",
    "# SCHEDULED_DEPARTURE, DISTANCE, departure_hour, early_morning\n",
    "\n",
    "# Prepare airlines enrichment DataFrame: rename IATA_CODE to AIRLINE_CODE and AIRLINE to AIRLINE_FULL_NAME\n",
    "airlines_enriched = airlines_df.select(\n",
    "    F.col(\"IATA_CODE\").alias(\"AIRLINE_CODE\"),\n",
    "    F.col(\"AIRLINE\").alias(\"AIRLINE_FULL_NAME\")\n",
    ")\n",
    "\n",
    "# Join final_transformed_df with airlines_enriched on AIRLINE code\n",
    "enriched_df = final_transformed_df.join(\n",
    "    airlines_enriched, \n",
    "    final_transformed_df.AIRLINE == airlines_enriched.AIRLINE_CODE, \n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Prepare origin airport enrichment DataFrame: rename IATA_CODE to ORIGIN_CODE and add full airport details\n",
    "airports_origin = airports_df.select(\n",
    "    F.col(\"IATA_CODE\").alias(\"ORIGIN_CODE\"),\n",
    "    F.col(\"AIRPORT\").alias(\"ORIGIN_AIRPORT_FULL\"),\n",
    "    F.col(\"CITY\").alias(\"ORIGIN_CITY\"),\n",
    "    F.col(\"STATE\").alias(\"ORIGIN_STATE\")\n",
    ")\n",
    "\n",
    "# Prepare destination airport enrichment DataFrame: rename IATA_CODE to DEST_CODE and add full airport details\n",
    "airports_dest = airports_df.select(\n",
    "    F.col(\"IATA_CODE\").alias(\"DEST_CODE\"),\n",
    "    F.col(\"AIRPORT\").alias(\"DESTINATION_AIRPORT_FULL\"),\n",
    "    F.col(\"CITY\").alias(\"DESTINATION_CITY\"),\n",
    "    F.col(\"STATE\").alias(\"DESTINATION_STATE\")\n",
    ")\n",
    "\n",
    "# Join with origin airport details on ORIGIN_AIRPORT key\n",
    "enriched_df = enriched_df.join(\n",
    "    airports_origin, \n",
    "    enriched_df.ORIGIN_AIRPORT == airports_origin.ORIGIN_CODE, \n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Join with destination airport details on DESTINATION_AIRPORT key\n",
    "enriched_df = enriched_df.join(\n",
    "    airports_dest, \n",
    "    enriched_df.DESTINATION_AIRPORT == airports_dest.DEST_CODE, \n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Drop duplicate key columns from enrichment (if desired)\n",
    "final_enriched_df = enriched_df.drop(\"AIRLINE_CODE\", \"ORIGIN_CODE\", \"DEST_CODE\")\n",
    "\n",
    "# Display the final enriched DataFrame and its schema\n",
    "final_enriched_df.show(5, truncate=False)\n",
    "final_enriched_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f06b5b-2856-4cfa-bcc0-0e13636b5e50",
   "metadata": {},
   "source": [
    "### Saving Final Enriched Dataset to Amazon S3 (Parquet Format)\n",
    "\n",
    "This step saves the enriched flight dataset (`final_enriched_df`) to Amazon S3 in Parquet format, ensuring efficient storage, faster querying, and ease of future retrieval for analysis or modeling tasks.\n",
    "\n",
    "**Destination Location:**\n",
    "\n",
    "```\n",
    "s3://final-csc555/parquet-data\n",
    "```\n",
    "\n",
    "- **File Format**: Parquet (columnar storage optimized for analytics)\n",
    "- **Overwrite Policy**: Existing data at the specified path will be overwritten.\n",
    "- **Accessibility**: Data stored on S3 for convenient future access and processing.\n",
    "\n",
    "The data is now ready and efficiently stored for subsequent use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e14fced2-74ce-497d-a39a-1d0eb366031f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T06:11:15.212715Z",
     "iopub.status.busy": "2025-03-13T06:11:15.212447Z",
     "iopub.status.idle": "2025-03-13T06:12:12.721064Z",
     "shell.execute_reply": "2025-03-13T06:12:12.720251Z",
     "shell.execute_reply.started": "2025-03-13T06:11:15.212683Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a3a1b600e14e64ba0b2aa2b2cbaa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final enriched transformed data written to S3 at: s3://final-csc555/parquet-data"
     ]
    }
   ],
   "source": [
    "final_enriched_df.write.mode(\"overwrite\").parquet(\"s3://final-csc555/parquet-data\")\n",
    "print(\"Final enriched transformed data written to S3 at: s3://final-csc555/parquet-data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b104738-4309-452f-8bc3-fc340e5a0eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7337b56-1c09-49f6-9a77-33e40c3828f0",
   "metadata": {},
   "source": [
    "---\n",
    "### Setting up Athena Client for Querying Data\n",
    "\n",
    "This step establishes a client connection to **AWS Athena** using `boto3`, leveraging IAM role credentials from our EMR environment. Athena allows efficient, SQL-based querying of datasets stored in Amazon S3.\n",
    "\n",
    "**Key components:**\n",
    "\n",
    "- **AWS Region**: `us-east-1`\n",
    "- **Athena Client**: Created using provided session credentials.\n",
    "- **Athena Output Location**: Results of queries will be stored in `final-csc555` bucket (must already exist).\n",
    "\n",
    "> **Note:**  \n",
    "> Ensure that the provided IAM credentials and session tokens are valid and have appropriate permissions.  \n",
    "> It is recommended to use environment credentials or IAM roles rather than embedding static credentials directly into scripts for better security practices.\n",
    "\n",
    "**Configured Athena Database:**  \n",
    "- Database location for storing query results set to your specified S3 bucket.\n",
    "\n",
    "The environment is now ready for executing SQL queries against your enriched dataset using Athena.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241dddc-5c11-4993-a510-677daffd5a58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T05:19:59.207997Z",
     "iopub.status.busy": "2025-03-13T05:19:59.207708Z",
     "iopub.status.idle": "2025-03-13T05:19:59.496246Z",
     "shell.execute_reply": "2025-03-13T05:19:59.495388Z",
     "shell.execute_reply.started": "2025-03-13T05:19:59.207946Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c22ead3739d4a78bbee0c4d5cd6d4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use boto3 to create an Athena client; on EMR, this will pick up the instance's IAM role credentials.\n",
    "AWS_REGION = 'us-east-1'\n",
    "athena_client = boto3.client('athena',\n",
    "\taws_access_key_id='************************', #your access key\n",
    "\taws_secret_access_key='**************************************', #your secret access key\n",
    "\taws_session_token='*******************************************', #your session token\n",
    "\tregion_name = AWS_REGION) # should be us-east-1 in most cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8eafef9-c629-4d7f-bad8-5bf8b75d498c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T06:02:55.333587Z",
     "iopub.status.busy": "2025-03-13T06:02:55.333297Z",
     "iopub.status.idle": "2025-03-13T06:02:55.399786Z",
     "shell.execute_reply": "2025-03-13T06:02:55.398731Z",
     "shell.execute_reply.started": "2025-03-13T06:02:55.333557Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc1324b9d2a46d2b72130d006b1fb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define your Athena output bucket for query results.\n",
    "# (This bucket must exist and the IAM role must have permission to write here.)\n",
    "ATHENA_OUTPUT = \"s3://final-csc555/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b91751ea-84ac-421a-b2ca-6fb212360ead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T06:14:29.928121Z",
     "iopub.status.busy": "2025-03-13T06:14:29.927854Z",
     "iopub.status.idle": "2025-03-13T06:14:30.010956Z",
     "shell.execute_reply": "2025-03-13T06:14:30.010145Z",
     "shell.execute_reply.started": "2025-03-13T06:14:29.928089Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb39d4cb47f4bed9c5e88564074aeba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use your database and table names.\n",
    "DATABASE_NAME = 'flight2_db'\n",
    "TABLE_NAME = 'flights_transformed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e53d1284-4f32-4391-890c-9f7b2233339c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T06:14:35.699702Z",
     "iopub.status.busy": "2025-03-13T06:14:35.699418Z",
     "iopub.status.idle": "2025-03-13T06:14:35.823907Z",
     "shell.execute_reply": "2025-03-13T06:14:35.822857Z",
     "shell.execute_reply.started": "2025-03-13T06:14:35.699668Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d0fb45139d458ba89c8c1cfc3800d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# New S3 location where your Parquet data is stored.\n",
    "PARQUET_DATA_LOCATION = \"s3://final-csc555/parquet-data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb718d-babf-48e8-9cf8-3ea28ab6d42a",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating an AWS Athena Database\n",
    "\n",
    "This step creates a new database in **AWS Athena**, preparing the environment for subsequent SQL queries and data analysis.\n",
    "\n",
    "**Process Details:**\n",
    "\n",
    "- **Database Creation**: Uses Athena to create a database, storing metadata to manage and query datasets efficiently.\n",
    "- **Execution Monitoring**: Monitors query execution status (`RUNNING`, `QUEUED`) until completion, ensuring the database is created successfully.\n",
    "- **Output Location**: Stores query execution results in a predefined Amazon S3 bucket (`ATHENA_OUTPUT`).\n",
    "\n",
    "After successful execution, the Athena database is ready for storing metadata tables and running queries against our enriched flight dataset stored on Amazon S3.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c916701-d9ac-4463-be9a-6fc41a65823e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T06:14:39.055112Z",
     "iopub.status.busy": "2025-03-13T06:14:39.054847Z",
     "iopub.status.idle": "2025-03-13T06:14:41.345186Z",
     "shell.execute_reply": "2025-03-13T06:14:41.344351Z",
     "shell.execute_reply.started": "2025-03-13T06:14:39.055082Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7858e2acd9b347959f67531d2e3efa12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query to create database:\n",
      "CREATE DATABASE IF NOT EXISTS flight2_db;\n",
      "Database created successfully."
     ]
    }
   ],
   "source": [
    "# Query 1: Create the database if it doesn't exist.\n",
    "create_database_query = f\"CREATE DATABASE IF NOT EXISTS {DATABASE_NAME};\"\n",
    "print(\"Executing query to create database:\")\n",
    "print(create_database_query)\n",
    "\n",
    "response = athena_client.start_query_execution(\n",
    "    QueryString=create_database_query,\n",
    "    ResultConfiguration={'OutputLocation': ATHENA_OUTPUT}\n",
    ")\n",
    "\n",
    "execution_id = response['QueryExecutionId']\n",
    "state = 'RUNNING'\n",
    "while state in ['RUNNING', 'QUEUED']:\n",
    "    time.sleep(2)\n",
    "    result = athena_client.get_query_execution(QueryExecutionId=execution_id)\n",
    "    state = result['QueryExecution']['Status']['State']\n",
    "\n",
    "if state != 'SUCCEEDED':\n",
    "    reason = result['QueryExecution']['Status'].get('StateChangeReason', 'Unknown')\n",
    "    raise Exception(f\"Database creation failed: {reason}\")\n",
    "\n",
    "print(\"Database created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c480784d-cb64-40aa-9ba1-cd2fbab0784a",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating an External Table in AWS Athena\n",
    "\n",
    "This step creates an **external table** in AWS Athena pointing to the flight dataset stored in Parquet format on Amazon S3. An external table allows querying the dataset directly from S3 without duplicating data storage.\n",
    "\n",
    "**Details:**\n",
    "\n",
    "- **Table Schema**: Defines column names and their respective data types (e.g., integers for scheduling details, strings for airline and airport names).\n",
    "- **Storage Format**: Data is stored as **Parquet**, optimizing query performance.\n",
    "- **Data Location**: Points directly to the enriched flight data (`PARQUET_DATA_LOCATION`) stored in S3.\n",
    "- **Query Execution Monitoring**: Ensures successful creation, providing clear feedback on success or failure.\n",
    "\n",
    "After successful creation, this table can be queried directly using Athena SQL, enabling efficient analytics and reporting.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25923ae8-9eab-4f08-904b-1a8d5cd4ff0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T06:14:44.722843Z",
     "iopub.status.busy": "2025-03-13T06:14:44.722598Z",
     "iopub.status.idle": "2025-03-13T06:14:47.019420Z",
     "shell.execute_reply": "2025-03-13T06:14:47.018687Z",
     "shell.execute_reply.started": "2025-03-13T06:14:44.722811Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502b1fe8b7864788b820f5b8da466ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query to create external table:\n",
      "CREATE EXTERNAL TABLE IF NOT EXISTS flights_transformed (\n",
      "  MONTH INT, \n",
      "  DAY_OF_WEEK INT,\n",
      "  AIRLINE STRING,\n",
      "  FLIGHT_NUMBER INT,\n",
      "  ORIGIN_AIRPORT STRING,\n",
      "  DESTINATION_AIRPORT STRING,\n",
      "  SCHEDULED_DEPARTURE INT,\n",
      "  DISTANCE INT,\n",
      "  departure_hour INT,\n",
      "  early_morning INT,\n",
      "  AIRLINE_FULL_NAME STRING,\n",
      "  ORIGIN_AIRPORT_FULL STRING,\n",
      "  ORIGIN_CITY STRING,\n",
      "  ORIGIN_STATE STRING,\n",
      "  DESTINATION_AIRPORT_FULL STRING,\n",
      "  DESTINATION_CITY STRING,\n",
      "  DESTINATION_STATE STRING\n",
      ")\n",
      "STORED AS PARQUET\n",
      "LOCATION 's3://final-csc555/parquet-data/';\n",
      "Athena table created successfully!"
     ]
    }
   ],
   "source": [
    "# Query 2: Create the external table.\n",
    "create_table_query = f\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS {TABLE_NAME} (\n",
    "  MONTH INT, \n",
    "  DAY_OF_WEEK INT,\n",
    "  AIRLINE STRING,\n",
    "  FLIGHT_NUMBER INT,\n",
    "  ORIGIN_AIRPORT STRING,\n",
    "  DESTINATION_AIRPORT STRING,\n",
    "  SCHEDULED_DEPARTURE INT,\n",
    "  DISTANCE INT,\n",
    "  departure_hour INT,\n",
    "  early_morning INT,\n",
    "  AIRLINE_FULL_NAME STRING,\n",
    "  ORIGIN_AIRPORT_FULL STRING,\n",
    "  ORIGIN_CITY STRING,\n",
    "  ORIGIN_STATE STRING,\n",
    "  DESTINATION_AIRPORT_FULL STRING,\n",
    "  DESTINATION_CITY STRING,\n",
    "  DESTINATION_STATE STRING\n",
    ")\n",
    "STORED AS PARQUET\n",
    "LOCATION '{PARQUET_DATA_LOCATION}';\n",
    "\"\"\"\n",
    "print(\"Executing query to create external table:\")\n",
    "print(create_table_query.strip())\n",
    "\n",
    "response = athena_client.start_query_execution(\n",
    "    QueryString=create_table_query,\n",
    "    QueryExecutionContext={'Database': DATABASE_NAME},\n",
    "    ResultConfiguration={'OutputLocation': ATHENA_OUTPUT}\n",
    ")\n",
    "\n",
    "execution_id = response['QueryExecutionId']\n",
    "state = 'RUNNING'\n",
    "while state in ['RUNNING', 'QUEUED']:\n",
    "    time.sleep(2)\n",
    "    result = athena_client.get_query_execution(QueryExecutionId=execution_id)\n",
    "    state = result['QueryExecution']['Status']['State']\n",
    "\n",
    "if state != 'SUCCEEDED':\n",
    "    reason = result['QueryExecution']['Status'].get('StateChangeReason', 'Unknown')\n",
    "    raise Exception(f\"Table creation failed: {reason}\")\n",
    "    \n",
    "print(\"Athena table created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f010bb9b-7514-4606-851e-17d3dcd4134c",
   "metadata": {},
   "source": [
    "---\n",
    "### Querying Data from Athena\n",
    "\n",
    "This step executes an Athena SQL query to retrieve data from the `flights_transformed` table:\n",
    "\n",
    "- **Query executed**:  \n",
    "  ```sql\n",
    "  SELECT * FROM flights_transformed LIMIT 900;\n",
    "  ```\n",
    "\n",
    "- **Purpose**: Quickly verify and inspect data from the external table, retrieving the first 900 rows.\n",
    "\n",
    "- **Execution and Result Retrieval**:\n",
    "  - Executes the query asynchronously.\n",
    "  - Monitors execution until completion.\n",
    "  - Retrieves results once the query succeeds.\n",
    "\n",
    "We can further process the returned data for analysis or visualization as required.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7e802cf1-5ac2-4f23-af6e-93bb62095176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T07:32:38.348277Z",
     "iopub.status.busy": "2025-03-13T07:32:38.347999Z",
     "iopub.status.idle": "2025-03-13T07:32:41.636054Z",
     "shell.execute_reply": "2025-03-13T07:32:41.635072Z",
     "shell.execute_reply.started": "2025-03-13T07:32:38.348241Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88225dbc8cd4a19b47613c4ed7407be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query:\n",
      "SELECT * FROM flights_transformed LIMIT 900;\n",
      "Query executed successfully. Fetching results..."
     ]
    }
   ],
   "source": [
    "# Define your query. Here, we select the first 900 rows.\n",
    "query_string = \"SELECT * FROM flights_transformed LIMIT 900;\"\n",
    "print(\"Executing query:\")\n",
    "print(query_string)\n",
    "\n",
    "# Start query execution.\n",
    "response = athena_client.start_query_execution(\n",
    "    QueryString=query_string,\n",
    "    QueryExecutionContext={'Database': DATABASE_NAME},\n",
    "    ResultConfiguration={'OutputLocation': ATHENA_OUTPUT}\n",
    ")\n",
    "\n",
    "execution_id = response['QueryExecutionId']\n",
    "\n",
    "# Poll until the query finishes.\n",
    "state = 'RUNNING'\n",
    "while state in ['RUNNING', 'QUEUED']:\n",
    "    time.sleep(2)\n",
    "    result = athena_client.get_query_execution(QueryExecutionId=execution_id)\n",
    "    state = result['QueryExecution']['Status']['State']\n",
    "\n",
    "if state != 'SUCCEEDED':\n",
    "    reason = result['QueryExecution']['Status'].get('StateChangeReason', 'Unknown')\n",
    "    raise Exception(f\"Query execution failed: {reason}\")\n",
    "\n",
    "print(\"Query executed successfully. Fetching results...\")\n",
    "\n",
    "# Fetch query results.\n",
    "result_response = athena_client.get_query_results(QueryExecutionId=execution_id)\n",
    "\n",
    "# Print the results.\n",
    "# Note: The results are returned in a structured format. You might need to process them further.\n",
    "#print(result_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f5f7e-2689-4984-9175-6233ac57c7b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Converting Athena Query Results to Pandas DataFrame  \n",
    "\n",
    "This step transforms the results obtained from AWS Athena into a structured, easy-to-use Pandas DataFrame:\n",
    "\n",
    "- Extracts column headers from Athena's result metadata.\n",
    "- Converts each row into a structured format, handling potential missing values appropriately.\n",
    "- Creates a DataFrame for further analysis, visualization, or reporting.\n",
    "\n",
    "The resulting DataFrame (`df`) provides a familiar and convenient format for subsequent data exploration and analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cc4022d8-6732-474c-9e34-c64ba53926de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T07:32:44.782991Z",
     "iopub.status.busy": "2025-03-13T07:32:44.782725Z",
     "iopub.status.idle": "2025-03-13T07:32:44.872491Z",
     "shell.execute_reply": "2025-03-13T07:32:44.871683Z",
     "shell.execute_reply.started": "2025-03-13T07:32:44.782964Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d70906651ec45e494a341fb4e7e6a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    month day_of_week  ... destination_city destination_state\n",
      "0      11           5  ...          Chicago                IL\n",
      "1      11           5  ...    San Francisco                CA\n",
      "2      11           5  ...          Houston                TX\n",
      "3      11           5  ...        San Diego                CA\n",
      "4      11           5  ...          Orlando                FL\n",
      "..    ...         ...  ...              ...               ...\n",
      "895    11           5  ...        San Diego                CA\n",
      "896    11           5  ...   Ft. Lauderdale                FL\n",
      "897    11           5  ...          Detroit                MI\n",
      "898    11           5  ...          Detroit                MI\n",
      "899    11           5  ...        Las Vegas                NV\n",
      "\n",
      "[900 rows x 17 columns]"
     ]
    }
   ],
   "source": [
    "# Convert the Athena query results to a Pandas DataFrame.\n",
    "rows = result_response['ResultSet']['Rows']\n",
    "\n",
    "# The first row contains column headers.\n",
    "headers = [col.get('VarCharValue', '') for col in rows[0]['Data']]\n",
    "data = []\n",
    "for row in rows[1:]:\n",
    "    # If a value is missing, Athena might return an empty dict.\n",
    "    row_data = [col.get('VarCharValue', None) for col in row['Data']]\n",
    "    data.append(row_data)\n",
    "\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd55308-74fd-4f80-b8c0-772226456af3",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Loading Athena Query Results Directly into Pandas\n",
    "\n",
    "This step reads the CSV results generated by Athena directly from the provided Amazon S3 path into a Pandas DataFrame:\n",
    "\n",
    "- **S3 Path:**  \n",
    "  ```\n",
    "  s3://final-csc555/23c9d842-bfa0-4e88-b3bb-0c84f3765b6e.csv\n",
    "  ```\n",
    "\n",
    "- **Method:** Uses `pandas.read_csv()` to efficiently load the CSV file directly from S3.\n",
    "\n",
    "- **Purpose:** Facilitates immediate exploratory data analysis, visualization, or further local processing.\n",
    "\n",
    "The resulting DataFrame (`df`) is ready for analysis and inspection.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a7218ed-beec-4773-90fd-e5c67ff4a4c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T20:18:42.904344Z",
     "iopub.status.busy": "2025-03-13T20:18:42.904111Z",
     "iopub.status.idle": "2025-03-13T20:18:48.213720Z",
     "shell.execute_reply": "2025-03-13T20:18:48.212741Z",
     "shell.execute_reply.started": "2025-03-13T20:18:42.904317Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975b04905353444bb5cb7ed94e128dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  day_of_week  ...   destination_city  destination_state\n",
      "0     11            5  ...            Chicago                 IL\n",
      "1     11            5  ...      San Francisco                 CA\n",
      "2     11            5  ...            Houston                 TX\n",
      "3     11            5  ...            Atlanta                 GA\n",
      "4     11            5  ...  Dallas-Fort Worth                 TX\n",
      "\n",
      "[5 rows x 17 columns]"
     ]
    }
   ],
   "source": [
    "# Replace with the exact path Athena provided for your query output.\n",
    "csv_s3_path = \"s3://final-csc555/23c9d842-bfa0-4e88-b3bb-0c84f3765b6e.csv\"\n",
    "\n",
    "# Using pandas to read CSV directly from S3:\n",
    "df = pd.read_csv(csv_s3_path)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6bd760-0ea5-48cc-85e8-b77f75417105",
   "metadata": {},
   "source": [
    "**We used two methods to load Athena query results serve different purposes:**\n",
    "\n",
    "### **Method 1: Using Athena’s Query Result API (`get_query_results`)**\n",
    "\n",
    "- **Purpose**: \n",
    "  - Quickly access small query results directly from Athena without additional setup.\n",
    "- **Use-case**:\n",
    "  - Ideal for small datasets or quick inspections.\n",
    "- **Limitations**:\n",
    "  - Not efficient for large datasets.\n",
    "  - Results require manual parsing into structured formats (like Pandas).\n",
    "\n",
    "### **Method 2: Loading directly from S3 using `pandas.read_csv`**\n",
    "\n",
    "- **Purpose**:\n",
    "  - Efficiently retrieve large query results stored by Athena in CSV format directly from S3.\n",
    "- **Use-case**:\n",
    "  - Preferred for larger datasets or analyses requiring ease and speed.\n",
    "- **Advantages**:\n",
    "  - Faster and more straightforward for larger queries.\n",
    "  - CSV is directly loaded into Pandas without extra parsing.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary:**\n",
    "\n",
    "- **Small dataset or quick checks:**  \n",
    "  → Use Athena’s API (`get_query_results`).\n",
    "\n",
    "- **Larger dataset or straightforward loading:**  \n",
    "  → Use `pandas.read_csv` from S3 path.\n",
    "\n",
    "We used both approaches for demonstration and to highlight the trade-offs in usability and scalability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786df5c-a3bf-4a89-bb56-16a5f63ab742",
   "metadata": {},
   "source": [
    "### Data Preparation for Machine Learning (Spark MLlib)\n",
    "\n",
    "This step prepares the data for machine learning using Spark MLlib:\n",
    "\n",
    "**1. Conversion to Spark DataFrame:**\n",
    "\n",
    "- Converted the Pandas DataFrame into a PySpark DataFrame (`spark_df`) for compatibility with Spark ML pipelines.\n",
    "\n",
    "**2. Data Type Casting:**\n",
    "\n",
    "- Numeric columns (`MONTH`, `DAY_OF_WEEK`, `SCHEDULED_DEPARTURE`, `DISTANCE`, `departure_hour`, `early_morning`) are explicitly converted to `IntegerType` for consistent modeling.\n",
    "\n",
    "**3. Creation of Target Variable (`IS_DELAYED`):**\n",
    "\n",
    "- Created a binary target variable `IS_DELAYED` indicating delayed flights.\n",
    "- For illustration, flights departing at or after 10 AM (`departure_hour >= 10`) are marked as delayed (`1`); otherwise, they are considered not delayed (`0`). Adjust this criterion based on your actual modeling needs.\n",
    "\n",
    "**4. Handling Missing Values:**\n",
    "\n",
    "- Dropped any remaining null values to ensure data quality for modeling.\n",
    "\n",
    "The resulting DataFrame is verified and ready for use in predictive modeling tasks with Spark MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2dc1d4-b4d1-4289-93ee-c9593f449f47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T20:36:56.686651Z",
     "iopub.status.busy": "2025-03-13T20:36:56.686393Z",
     "iopub.status.idle": "2025-03-13T20:38:30.305715Z",
     "shell.execute_reply": "2025-03-13T20:38:30.304829Z",
     "shell.execute_reply.started": "2025-03-13T20:36:56.686623Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6a328c512b475fb7b46e689f62bcc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month: long (nullable = true)\n",
      " |-- day_of_week: long (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight_number: long (nullable = true)\n",
      " |-- origin_airport: string (nullable = true)\n",
      " |-- destination_airport: string (nullable = true)\n",
      " |-- scheduled_departure: long (nullable = true)\n",
      " |-- distance: long (nullable = true)\n",
      " |-- departure_hour: long (nullable = true)\n",
      " |-- early_morning: long (nullable = true)\n",
      " |-- airline_full_name: string (nullable = true)\n",
      " |-- origin_airport_full: string (nullable = true)\n",
      " |-- origin_city: string (nullable = true)\n",
      " |-- origin_state: string (nullable = true)\n",
      " |-- destination_airport_full: string (nullable = true)\n",
      " |-- destination_city: string (nullable = true)\n",
      " |-- destination_state: string (nullable = true)\n",
      "\n",
      "+-----+-----------+-------+-------------+--------------+-------------------+-------------------+--------+--------------+-------------+--------------------+--------------------+-----------+------------+------------------------+-----------------+-----------------+\n",
      "|month|day_of_week|airline|flight_number|origin_airport|destination_airport|scheduled_departure|distance|departure_hour|early_morning|   airline_full_name| origin_airport_full|origin_city|origin_state|destination_airport_full| destination_city|destination_state|\n",
      "+-----+-----------+-------+-------------+--------------+-------------------+-------------------+--------+--------------+-------------+--------------------+--------------------+-----------+------------+------------------------+-----------------+-----------------+\n",
      "|   11|          5|     UA|          407|           LAX|                ORD|                625|    1744|             6|            0|United Air Lines ...|Los Angeles Inter...|Los Angeles|          CA|    Chicago O'Hare In...|          Chicago|               IL|\n",
      "|   11|          5|     UA|          414|           LAX|                SFO|                625|     337|             6|            0|United Air Lines ...|Los Angeles Inter...|Los Angeles|          CA|    San Francisco Int...|    San Francisco|               CA|\n",
      "|   11|          5|     WN|         4051|           TPA|                HOU|                625|     781|             6|            0|Southwest Airline...|Tampa Internation...|      Tampa|          FL|    William P. Hobby ...|          Houston|               TX|\n",
      "|   11|          5|     DL|          891|           MIA|                ATL|                625|     594|             6|            0|Delta Air Lines Inc.|Miami Internation...|      Miami|          FL|    Hartsfield-Jackso...|          Atlanta|               GA|\n",
      "|   11|          5|     EV|         2826|           JAN|                DFW|                625|     408|             6|            0|Atlantic Southeas...|Jackson-Evers Int...|    Jackson|          MS|    Dallas/Fort Worth...|Dallas-Fort Worth|               TX|\n",
      "+-----+-----------+-------+-------------+--------------+-------------------+-------------------+--------+--------------+-------------+--------------------+--------------------+-----------+------------+------------------------+-----------------+-----------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# First, convert Pandas DataFrame to PySpark DataFrame\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "spark_df.printSchema()\n",
    "spark_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d64b1-7e87-4f81-bb10-64ad8bb9f41e",
   "metadata": {},
   "source": [
    "Data Pre-processing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c8a5c7f-b6b9-4656-83b8-e48421199ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T20:50:17.575599Z",
     "iopub.status.busy": "2025-03-13T20:50:17.575361Z",
     "iopub.status.idle": "2025-03-13T20:51:05.016377Z",
     "shell.execute_reply": "2025-03-13T20:51:05.015247Z",
     "shell.execute_reply.started": "2025-03-13T20:50:17.575572Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c637f14a2547f8ac4464000a380f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------------------+--------+--------------+-------------+----------+\n",
      "|MONTH|DAY_OF_WEEK|SCHEDULED_DEPARTURE|DISTANCE|departure_hour|early_morning|IS_DELAYED|\n",
      "+-----+-----------+-------------------+--------+--------------+-------------+----------+\n",
      "|   11|          5|                625|    1744|             6|            0|         0|\n",
      "|   11|          5|                625|     337|             6|            0|         0|\n",
      "|   11|          5|                625|     781|             6|            0|         0|\n",
      "|   11|          5|                625|     594|             6|            0|         0|\n",
      "|   11|          5|                625|     408|             6|            0|         0|\n",
      "+-----+-----------+-------------------+--------+--------------+-------------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Convert numeric columns to integer type\n",
    "numeric_cols = ['MONTH', 'DAY_OF_WEEK', 'SCHEDULED_DEPARTURE', 'DISTANCE', 'departure_hour', 'early_morning']\n",
    "for c in numeric_cols:\n",
    "    spark_df = spark_df.withColumn(c, col(c).cast(IntegerType()))\n",
    "\n",
    "# Create target variable IS_DELAYED\n",
    "# For simplicity, let's assume departure_hour >= 15 is a delayed flight (you can modify this based on real delay criteria)\n",
    "spark_df = spark_df.withColumn(\n",
    "    \"IS_DELAYED\", \n",
    "    (col(\"departure_hour\") >= 15).cast(\"integer\")\n",
    ")\n",
    "\n",
    "# Drop nulls if any\n",
    "spark_df = spark_df.na.drop()\n",
    "\n",
    "spark_df.select(numeric_cols + ['IS_DELAYED']).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd488872-accb-471f-8a5f-2f390e7e569f",
   "metadata": {},
   "source": [
    "Feature Encoding  (Categorical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1260a552-834e-43f9-b9c3-4db3a993e1a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T20:40:38.421561Z",
     "iopub.status.busy": "2025-03-13T20:40:38.421161Z",
     "iopub.status.idle": "2025-03-13T20:40:38.549190Z",
     "shell.execute_reply": "2025-03-13T20:40:38.548112Z",
     "shell.execute_reply.started": "2025-03-13T20:40:38.421512Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437fd450f56642c7853da027cd39710a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MONTH: integer (nullable = true)\n",
      " |-- DAY_OF_WEEK: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight_number: long (nullable = true)\n",
      " |-- origin_airport: string (nullable = true)\n",
      " |-- destination_airport: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- departure_hour: integer (nullable = true)\n",
      " |-- early_morning: integer (nullable = true)\n",
      " |-- airline_full_name: string (nullable = true)\n",
      " |-- origin_airport_full: string (nullable = true)\n",
      " |-- origin_city: string (nullable = true)\n",
      " |-- origin_state: string (nullable = true)\n",
      " |-- destination_airport_full: string (nullable = true)\n",
      " |-- destination_city: string (nullable = true)\n",
      " |-- destination_state: string (nullable = true)\n",
      " |-- IS_DELAYED: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93715bc8-0b91-49d9-a858-6cf983cc2e6c",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Pipeline: Feature Encoding and Vector Assembly\n",
    "\n",
    "This step builds a **Spark MLlib pipeline** to transform categorical and numeric columns into a unified feature vector, ready for predictive modeling:\n",
    "\n",
    "**Pipeline Components:**\n",
    "\n",
    "- **Categorical Feature Encoding:**\n",
    "  - Converts categorical columns (`airline_full_name`, `origin_airport_full`, `destination_airport_full`) into numeric indices (`StringIndexer`) and then encodes them into vector form (`OneHotEncoder`).\n",
    "\n",
    "- **Vector Assembler**:\n",
    "  - Combines numeric columns (`MONTH`, `DAY_OF_WEEK`, `SCHEDULED_DEPARTURE`, `DISTANCE`, `departure_hour`, `early_morning`) and categorical feature vectors into a single unified feature vector.\n",
    "\n",
    "**Pipeline Execution**:\n",
    "\n",
    "- Fits the pipeline on the dataset to learn encoding schemes and applies transformations.\n",
    "- Results in a machine learning-ready DataFrame (`ml_df`) with:\n",
    "  - **`features`**: Encoded feature vector.\n",
    "  - **`IS_DELAYED`**: Target variable for model training.\n",
    "\n",
    "The dataset is now ready for modeling with Spark MLlib classifiers or regressors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7f9b1f2-5d93-429f-9df1-ae939e46b8c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T20:51:14.755358Z",
     "iopub.status.busy": "2025-03-13T20:51:14.755127Z",
     "iopub.status.idle": "2025-03-13T20:51:36.160563Z",
     "shell.execute_reply": "2025-03-13T20:51:36.159610Z",
     "shell.execute_reply.started": "2025-03-13T20:51:14.755332Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49900090fc2c48e38a2f3c39e7ddf98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------+----------+\n",
      "|features                                                                           |IS_DELAYED|\n",
      "+-----------------------------------------------------------------------------------+----------+\n",
      "|(770,[0,1,2,3,4,11,24,342,662,719],[11.0,5.0,625.0,1744.0,6.0,1.0,1.0,1.0,1.0,1.0])|0         |\n",
      "|(770,[0,1,2,3,4,11,24,346,662,716],[11.0,5.0,625.0,337.0,6.0,1.0,1.0,1.0,1.0,1.0]) |0         |\n",
      "|(770,[0,1,2,3,4,6,45,369,664,717],[11.0,5.0,625.0,781.0,6.0,1.0,1.0,1.0,1.0,1.0])  |0         |\n",
      "|(770,[0,1,2,3,4,7,44,341,664,720],[11.0,5.0,625.0,594.0,6.0,1.0,1.0,1.0,1.0,1.0])  |0         |\n",
      "|(770,[0,1,2,3,4,10,113,343,703,717],[11.0,5.0,625.0,408.0,6.0,1.0,1.0,1.0,1.0,1.0])|0         |\n",
      "+-----------------------------------------------------------------------------------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Define categorical columns clearly from your schema\n",
    "categorical_cols = [\n",
    "    \"airline_full_name\", \n",
    "    \"origin_airport_full\",\n",
    "    \"destination_airport_full\",\n",
    "    \"origin_state\",\n",
    "    \"destination_state\"\n",
    "]\n",
    "\n",
    "# StringIndexer and OneHotEncoder for categorical columns\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid='keep') for col in categorical_cols]\n",
    "\n",
    "encoders = [OneHotEncoder(inputCol=f\"{col}_idx\", outputCol=f\"{col}_vec\") for col in categorical_cols]\n",
    "\n",
    "# Combine numeric and encoded categorical features into a single feature vector\n",
    "assembler_inputs = [\n",
    "    \"MONTH\",\n",
    "    \"DAY_OF_WEEK\",\n",
    "    \"SCHEDULED_DEPARTURE\",\n",
    "    \"DISTANCE\",\n",
    "    \"departure_hour\",\n",
    "    \"early_morning\"\n",
    "] + [f\"{col}_vec\" for col in categorical_cols]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "# Final pipeline definition\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "\n",
    "# Fit the pipeline model and transform data\n",
    "pipeline_model = pipeline.fit(spark_df)\n",
    "ml_df = pipeline_model.transform(spark_df)\n",
    "\n",
    "ml_df.select(\"features\", \"IS_DELAYED\").show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14689f61-00b3-4128-aaeb-f2f8f1e9ea2b",
   "metadata": {},
   "source": [
    "---\n",
    "### Splitting Data into Training and Testing Sets\n",
    "\n",
    "This step divides the prepared dataset into:\n",
    "\n",
    "- **Training set (`train_df`)**: 80% of data, used to train and validate machine learning models.\n",
    "- **Testing Set (`test_df`)**: Remaining 20%, used for evaluating the model’s performance on unseen data.\n",
    "\n",
    "The random split ensures reproducibility (`seed=42`). The resulting datasets can be directly used for training, evaluating, and tuning machine learning models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2b30b60-c9ba-4d5a-a855-8b2e969778bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T20:51:40.995075Z",
     "iopub.status.busy": "2025-03-13T20:51:40.994791Z",
     "iopub.status.idle": "2025-03-13T20:51:41.062995Z",
     "shell.execute_reply": "2025-03-13T20:51:41.062257Z",
     "shell.execute_reply.started": "2025-03-13T20:51:40.995036Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc51a73bef0490b945c71b82f674b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df = ml_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aeec72-af86-455b-88c8-526d12354387",
   "metadata": {},
   "source": [
    "---\n",
    "### Checking the Target Variable Distribution (Class Balance)\n",
    "\n",
    "This step examines the distribution of the target variable (`IS_DELAYED`):\n",
    "\n",
    "- **Class Balance Check**:  \n",
    "  Counts the number of delayed (`1`) and non-delayed (`0`) flights. Helps assess if class imbalance exists, guiding potential modeling decisions such as resampling or weighting.\n",
    "\n",
    "- **Data Type Casting**: Ensures the target variable (`IS_DELAYED`) is explicitly cast as an integer, which is required for classification modeling with Spark MLlib.\n",
    "\n",
    "Understanding class distribution ensures proper evaluation metrics and modeling decisions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf638c2e-1dfb-4692-b437-8fd0a5f69d13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T20:51:45.380862Z",
     "iopub.status.busy": "2025-03-13T20:51:45.380634Z",
     "iopub.status.idle": "2025-03-13T20:51:48.707836Z",
     "shell.execute_reply": "2025-03-13T20:51:48.706779Z",
     "shell.execute_reply.started": "2025-03-13T20:51:45.380836Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b63994411a49d086102023dd760fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|IS_DELAYED| count|\n",
      "+----------+------+\n",
      "|         1|203139|\n",
      "|         0|296861|\n",
      "+----------+------+"
     ]
    }
   ],
   "source": [
    "spark_df.groupBy(\"IS_DELAYED\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03804f6a-1534-4381-9edb-3a87e1b0e757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T20:52:42.790821Z",
     "iopub.status.busy": "2025-03-13T20:52:42.790580Z",
     "iopub.status.idle": "2025-03-13T20:52:42.846991Z",
     "shell.execute_reply": "2025-03-13T20:52:42.845116Z",
     "shell.execute_reply.started": "2025-03-13T20:52:42.790793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce8f488f27b4e6a88c10e25defa7924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_df = spark_df.withColumn(\"IS_DELAYED\", spark_df[\"IS_DELAYED\"].cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d10ff33-76b6-418b-af0b-2e0d0bf0fcf3",
   "metadata": {},
   "source": [
    "---\n",
    "### Logistic Regression Model Training and Prediction\n",
    "\n",
    "This step trains a **Logistic Regression** model using Spark MLlib and evaluates it on the test set:\n",
    "\n",
    "- **Model Details**:\n",
    "  - Predicts flight delays (`IS_DELAYED`) based on the assembled feature vector.\n",
    "  - Uses binomial logistic regression for binary classification.\n",
    "\n",
    "- **Output Columns in Predictions**:\n",
    "  - **`IS_DELAYED`**: Actual label.\n",
    "  - **`prediction`**: Predicted class (0 or 1).\n",
    "  - **`probability`**: Probability of each class (delayed vs. not delayed).\n",
    "  - **`rawPrediction`**: Raw scores before conversion to probabilities.\n",
    "\n",
    "The resulting predictions allow evaluating model performance and effectiveness in predicting flight delays.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa17a17d-1fa0-4714-9536-7fffaae5d478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T20:52:47.836234Z",
     "iopub.status.busy": "2025-03-13T20:52:47.835981Z",
     "iopub.status.idle": "2025-03-13T20:54:15.563630Z",
     "shell.execute_reply": "2025-03-13T20:54:15.562037Z",
     "shell.execute_reply.started": "2025-03-13T20:52:47.836185Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3895c929d440b99ec63fe1a8775e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+----------------------------------------+\n",
      "|IS_DELAYED|prediction|probability|rawPrediction                           |\n",
      "+----------+----------+-----------+----------------------------------------+\n",
      "|0         |0.0       |[1.0,0.0]  |[111.4583100148675,-111.4583100148675]  |\n",
      "|0         |0.0       |[1.0,0.0]  |[114.90449511213194,-114.90449511213194]|\n",
      "|0         |0.0       |[1.0,0.0]  |[340.46076885284083,-340.46076885284083]|\n",
      "|0         |0.0       |[1.0,0.0]  |[107.81184469681534,-107.81184469681534]|\n",
      "|0         |0.0       |[1.0,0.0]  |[326.8666750088467,-326.8666750088467]  |\n",
      "+----------+----------+-----------+----------------------------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='IS_DELAYED', family='binomial')\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select('IS_DELAYED', 'prediction', 'probability', 'rawPrediction').show(5, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c582d6-f6fc-42c7-bc78-f130937c3ad8",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Evaluation Metrics\n",
    "\n",
    "This step evaluates the Logistic Regression model's performance using key classification metrics:\n",
    "\n",
    "- **Accuracy**: Measures the overall correctness of predictions.\n",
    "- **AUC (Area Under ROC Curve)**: Indicates the model’s capability to distinguish between delayed and non-delayed flights (higher AUC indicates better predictive power).\n",
    "\n",
    "Additionally, a **Confusion Matrix** is generated to visualize detailed prediction outcomes\n",
    "\n",
    "These metrics collectively provide insights into the accuracy and reliability of the predictive model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81361d3a-1c86-4d04-8fd2-6299cd4ac2e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-13T20:57:30.995718Z",
     "iopub.status.busy": "2025-03-13T20:57:30.995465Z",
     "iopub.status.idle": "2025-03-13T20:57:56.388658Z",
     "shell.execute_reply": "2025-03-13T20:57:56.387987Z",
     "shell.execute_reply.started": "2025-03-13T20:57:30.995691Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e8ba6219c84aa499dd237f2176554b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "AUC: 1.0000\n",
      "+----------+----------+-----+\n",
      "|IS_DELAYED|prediction|count|\n",
      "+----------+----------+-----+\n",
      "|         1|       1.0|40654|\n",
      "|         0|       0.0|59548|\n",
      "|         1|       0.0|    2|\n",
      "|         0|       1.0|    1|\n",
      "+----------+----------+-----+"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Accuracy\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"IS_DELAYED\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# AUC\n",
    "evaluator_auc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"IS_DELAYED\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\"\n",
    ")\n",
    "auc = evaluator_auc.evaluate(predictions)\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "predictions.groupBy('IS_DELAYED', 'prediction').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ff0d78-3c4d-49b4-ae08-cfa00091f9ed",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Performance Summary\n",
    "\n",
    "The Logistic Regression model shows exceptionally high performance:\n",
    "\n",
    "- **Accuracy:** `100%`\n",
    "- **AUC (Area Under ROC):** `100%`\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "| Actual (`IS_DELAYED`) | Predicted (`prediction`) | Count  | Interpretation        |\n",
    "|-----------------------|--------------------------|--------|-----------------------|\n",
    "| 1                     | 1                        | 40,654 | True Positives ✅     |\n",
    "| 0                     | 0                        | 59,548 | True Negatives ✅     |\n",
    "| 0                     | 1                        | 2      | False Positives ❌    |\n",
    "| 1                     | 0                        | 1      | False Negatives ❌    |\n",
    "\n",
    "**Insights:**\n",
    "\n",
    "- Nearly perfect classification accuracy.\n",
    "- Extremely high AUC indicates excellent model capability to distinguish between delayed and non-delayed flights.\n",
    "- The very low count of misclassified instances suggests minimal errors, indicating the model is highly effective on the current dataset.\n",
    "\n",
    "**Recommendation:**  \n",
    "Validate this high performance on additional or unseen data to confirm generalizability.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58fadc-dc19-446d-b267-335c8cba061b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd7135-fae8-475c-93de-4002dc38e893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893dc94c-30dd-444f-88f9-24d4d442a83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8968068c-5b11-456d-bd3a-9b3bf3df7000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f6b82-2f8d-4b75-9603-65d51434946b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5b575-7aaa-491e-85b1-9595c1437515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f7c02-ed20-4c69-a213-a55e94ff275e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a0ed9-e2d4-4bac-af88-c78bada039ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c2487-7a78-4c0d-a187-fb04d2a3e2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb55c7-4fc2-4126-ae6d-70bee7c99f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa38b3-b87e-4b0f-b020-76a2e782de6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370bf8a8-f2fd-46d7-9ee4-cac3981009ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
